[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "VIMuRe",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023)."
  },
  {
    "objectID": "index.html#in-brief",
    "href": "index.html#in-brief",
    "title": "VIMuRe",
    "section": "📝 In brief",
    "text": "📝 In brief\n\nInput: multiply-sampled social network data as an edgelist or an igraph object.\nOutput: a fitted latent network model that can be used to obtain samples or a point-estimate network (an igraph object) from the posterior distribution of the fitted model."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "VIMuRe",
    "section": "Getting started",
    "text": "Getting started\n\nHead to the 📦 Installation page to learn how to install the package (either R or Python).\nCheck out the 💻 Tutorials page to learn how to use the package."
  },
  {
    "objectID": "latest/install.html",
    "href": "latest/install.html",
    "title": "📦 Installation",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nVIMuRe is available in both R and Python. The R implementation is a wrapper around the Python implementation. Both packages are in active development and are not yet on CRAN or PyPI. Use the installation instructions below to install the latest development version.\nChoose your language:"
  },
  {
    "objectID": "latest/install.html#step-01-install-reticulate",
    "href": "latest/install.html#step-01-install-reticulate",
    "title": "📦 Installation",
    "section": "Step 01: Install reticulate",
    "text": "Step 01: Install reticulate\nOpen your R console and type the following command:\ninstall.packages(\"reticulate\")\n\n\n\n\n\n\nWhy do I need this package?\n\n\n\n\n\n\nOur core code is written in python, so we use reticulate to integrate our model in R. This package allows you to use Python within your R session in a seamless, high-performance interoperable way.\nreticulate will look for the python installed on your computer. If for some reason it cannot find it, you may be prompted to download and install miniconda.\n\nminiconda is the recommended installation method for most users, as it is easier to ensure that the newly installed python is isolated from other python installs you have in your system.\nIf you initially declined the miniconda installation prompt, you can later manually install miniconda by running reticulate::install_miniconda()."
  },
  {
    "objectID": "latest/install.html#step-02-install-the-latest-vimure-v0.1",
    "href": "latest/install.html#step-02-install-the-latest-vimure-v0.1",
    "title": "📦 Installation",
    "section": "Step 02: Install the latest vimure (v0.1)",
    "text": "Step 02: Install the latest vimure (v0.1)\nIn your R console, type the following commands:\nrequire(devtools)\ndevtools::install_github(\"latentnetworks/vimure\", subdir=\"src/R\", ref=\"main\")\nCheck out devtools package documentation if you are not familiar with it."
  },
  {
    "objectID": "latest/install.html#step-03-install-the-python-package",
    "href": "latest/install.html#step-03-install-the-python-package",
    "title": "📦 Installation",
    "section": "Step 03: Install the Python package",
    "text": "Step 03: Install the Python package\nYou must install the python package before using the R package. This is because the R package is a wrapper around the Python package. You can do this without leaving R, though. Just type the following command in your R console:\nrequire(vimure)\nvimure::install_vimure()\nIf you are not using RStudio, i.e., you are using R in the terminal, you may need to restart your R session after installing the Python package.\nNot a fan of having to do this python setup? Please add a message to this discussion to tell us you would like to see an easier installation process for R."
  },
  {
    "objectID": "latest/people.html",
    "href": "latest/people.html",
    "title": "People",
    "section": "",
    "text": "Who we are\nThe people behind the conception, development, and maintenance of VIMuRe are listed below.\n\n\n\n\n\nDr. Caterina De Bacco CyberValley Research Group Leader MPI for Intelligent Systems 🧑‍💻 core package developer\n\n\n\n\n\n\nMartina Contisciani Ph.D. Student MPI for Intelligent Systems 🧑‍💻 core package developer\n\n\n\n\n\n\nDr. Jon Cardoso-Silva Assist. Prof. Lecturer LSE Data Science Institute 🧑‍💻 core package developer\n\n\n\n\n\n\nDr. Hadiseh Safdari Postdoctoral Researcher MPI for Intelligent Systems\n\n\n\n\n\n\nDiego Baptista Theuerkauf Ph.D. Student MPI for Intelligent Systems\n\n\n\n\n\n\nGabriela Lima Borges Data Scientist / Guest Researcher MPI for Evolutionary Anthropology 🧑‍💻 core package developer\n\n\n\n\n\n\nDr. Tracy Sweet Associate Professor UMD College of Education\n\n\n\n\n\n\nDr. Jean-Gabriel Young Assistant Professor The University of Vermont\n\n\n\n\n\n\nDr. Jeremy Koster Professor University of Cincinnati\n\n\n\n\n\n\nDr. Cody T. Ross Research Scientist MPI for Evolutionary Anthropology\n\n\n\n\n\n\nDr. Richard McElreath Professor MPI for Evolutionary Anthropology\n\n\n\n\n\n\nDr. Daniel Redhead Research Scientist MPI for Evolutionary Anthropology\n\n\n\n\n\n\nDr. Eleanor A. Power Assistant Professor LSE Department of Methodology"
  },
  {
    "objectID": "latest/pkg-docs.html",
    "href": "latest/pkg-docs.html",
    "title": "📚 Package Documentation",
    "section": "",
    "text": "Check the functions, parameters and examples of the package.\nChoose your favourite language:\n\n\n  \n\nR\n\n\n\n  \n\nPython"
  },
  {
    "objectID": "latest/pkg-docs/python.html",
    "href": "latest/pkg-docs/python.html",
    "title": "📚 Python package documentation",
    "section": "",
    "text": "Module vimure.model\n\n\n\nInference model\n\n\n\n\nclass VimureModel(\n    undirected: bool = False,\n    mutuality: bool = True,\n    convergence_tol: float = 0.1,\n    decision: int = 1,\n    verbose: bool = False\n):\nViMuRe\nFit a probabilistic generative model to double sampled networks. It returns reliability parameters for the reporters (theta), average interactions for the links (lambda) and the estimate of the true and unknown network (rho). The inference is performed with a Variational Inference approach.\n📝 note: this closely follows the scikit-learn structure of classes\nParameters\n\nundirected : boolean\nWhether the network is undirected.\nmutuality : boolean\nWhether to use the mutuality parameter.\nconvergence_tol : float\nControls when to stop the optimisation algorithm (CAVI)\n\n\n\n\nsklearn.base.TransformerMixin\nsklearn.utils._set_output._SetOutputMixin\nsklearn.base.BaseEstimator\n\n\n\n\n\n\n\ndef fit(\n    self,\n    X,\n    theta_prior=(0.1, 0.1),\n    lambda_prior=(10.0, 10.0),\n    eta_prior=(0.5, 1.0),\n    rho_prior=None,\n    seed: int = None,\n    **extra_params\n):\nParameters\n\nX : ndarray\nNetwork adjacency tensor.\ntheta_prior : 2D tuple\nShape and scale hyperparameters for variable theta\nlambda_prior : 2D tuple\nShape and scale hyperparameters for variable lambda\neta_prior : 2D tuple\nShape and scale hyperparameters for variable eta\nrho_prior : None/ndarray\nArray with prior values of the rho parameter - if ndarray.\nR : ndarray (optional)\na multidimensional array L x N x N x M indicating which reports to consider\nK : None/int (optional)\nValue of the maximum entry of the network - i\nEPS : float (optional)\nWhite noise. Default: 1e-12\nbias0 : float (optional)\nBias for rho_prior entry 0. Default: 0.2\nmax_iter : int (optional)\nMaximum number of iteration steps before aborting. Default=500\n\nReturns\n\nself : object\nReturns the instance itself.\n\n\n\n\ndef get_inferred_model(self, method='rho_max', threshold=None):\nEstimate Y\nUse this function to reconstruct the Y matrix with a fitted vimure model. It will use model.rho_f values to extract an estimated Y matrix.\n\nrho_max: Assign the value of the highest probability\nrho_mean: Expected value of the discrete distribution\nfixed_threshold: Check if the probability is higher than a threshold (Only for K=2)\nheuristic_threshold: Calculate and use the best threshold (Only for K=2)\n\nParameters\n\nmodel : vm.model.VimureModel\nA vm.model.VimureModel object\nmethod : str\nA character string indicating which method is to be computed.\n\nOne of “rho_max” (default), “rho_mean”, “fixed_threshold” or “heuristic_threshold”. - threshold : float\nA threshold to be used when method = \"fixed_threshold\".\nReturns\n\nY : ndarray\n \n\n\n\n\ndef get_posterior_estimates(self):\nGet posterior estimates\nUse this function to get the posterior estimates of the model parameters\nReturns\n\nposterior_estimates : dict\nA dictionary with the posterior estimates of the model parameters (nu, theta, lambda, rho). See 💻 Tutorial 02.\n\n\n\n\ndef sample_inferred_model(self, N=1, seed=None):\nSample Y trials from rho distribution\nUse this function to sample Y trials with a fitted vimure model. It will use model.rho_f as the probabilities of a discrete distribution.\nParameters\n\nmodel : vm.model.VimureModel\nA vm.model.VimureModel object\nN : int\nNumber of trials\nseed : int\nA pseudo generator seed\n\nReturns\n\nY : List[ndarray]\nA list of trials"
  },
  {
    "objectID": "latest/pkg-docs/python.html#classes",
    "href": "latest/pkg-docs/python.html#classes",
    "title": "📚 Python package documentation",
    "section": "",
    "text": "class VimureModel(\n    undirected: bool = False,\n    mutuality: bool = True,\n    convergence_tol: float = 0.1,\n    decision: int = 1,\n    verbose: bool = False\n):\nViMuRe\nFit a probabilistic generative model to double sampled networks. It returns reliability parameters for the reporters (theta), average interactions for the links (lambda) and the estimate of the true and unknown network (rho). The inference is performed with a Variational Inference approach.\n📝 note: this closely follows the scikit-learn structure of classes\nParameters\n\nundirected : boolean\nWhether the network is undirected.\nmutuality : boolean\nWhether to use the mutuality parameter.\nconvergence_tol : float\nControls when to stop the optimisation algorithm (CAVI)\n\n\n\n\nsklearn.base.TransformerMixin\nsklearn.utils._set_output._SetOutputMixin\nsklearn.base.BaseEstimator\n\n\n\n\n\n\n\ndef fit(\n    self,\n    X,\n    theta_prior=(0.1, 0.1),\n    lambda_prior=(10.0, 10.0),\n    eta_prior=(0.5, 1.0),\n    rho_prior=None,\n    seed: int = None,\n    **extra_params\n):\nParameters\n\nX : ndarray\nNetwork adjacency tensor.\ntheta_prior : 2D tuple\nShape and scale hyperparameters for variable theta\nlambda_prior : 2D tuple\nShape and scale hyperparameters for variable lambda\neta_prior : 2D tuple\nShape and scale hyperparameters for variable eta\nrho_prior : None/ndarray\nArray with prior values of the rho parameter - if ndarray.\nR : ndarray (optional)\na multidimensional array L x N x N x M indicating which reports to consider\nK : None/int (optional)\nValue of the maximum entry of the network - i\nEPS : float (optional)\nWhite noise. Default: 1e-12\nbias0 : float (optional)\nBias for rho_prior entry 0. Default: 0.2\nmax_iter : int (optional)\nMaximum number of iteration steps before aborting. Default=500\n\nReturns\n\nself : object\nReturns the instance itself.\n\n\n\n\ndef get_inferred_model(self, method='rho_max', threshold=None):\nEstimate Y\nUse this function to reconstruct the Y matrix with a fitted vimure model. It will use model.rho_f values to extract an estimated Y matrix.\n\nrho_max: Assign the value of the highest probability\nrho_mean: Expected value of the discrete distribution\nfixed_threshold: Check if the probability is higher than a threshold (Only for K=2)\nheuristic_threshold: Calculate and use the best threshold (Only for K=2)\n\nParameters\n\nmodel : vm.model.VimureModel\nA vm.model.VimureModel object\nmethod : str\nA character string indicating which method is to be computed.\n\nOne of “rho_max” (default), “rho_mean”, “fixed_threshold” or “heuristic_threshold”. - threshold : float\nA threshold to be used when method = \"fixed_threshold\".\nReturns\n\nY : ndarray\n \n\n\n\n\ndef get_posterior_estimates(self):\nGet posterior estimates\nUse this function to get the posterior estimates of the model parameters\nReturns\n\nposterior_estimates : dict\nA dictionary with the posterior estimates of the model parameters (nu, theta, lambda, rho). See 💻 Tutorial 02.\n\n\n\n\ndef sample_inferred_model(self, N=1, seed=None):\nSample Y trials from rho distribution\nUse this function to sample Y trials with a fitted vimure model. It will use model.rho_f as the probabilities of a discrete distribution.\nParameters\n\nmodel : vm.model.VimureModel\nA vm.model.VimureModel object\nN : int\nNumber of trials\nseed : int\nA pseudo generator seed\n\nReturns\n\nY : List[ndarray]\nA list of trials"
  },
  {
    "objectID": "latest/pkg-docs/python.html#functions",
    "href": "latest/pkg-docs/python.html#functions",
    "title": "📚 Python package documentation",
    "section": "Functions",
    "text": "Functions\n\nbuild_custom_theta\ndef build_custom_theta(\n    gt_network: BaseSyntheticNetwork,\n    theta_ratio: float = 0.5,\n    exaggeration_type: str = 'over',\n    seed: int = None\n):\nInstead of the regular generative model for theta ~ Gamma(sh,sc), create a more extreme scenario where some percentage of reporters are exaggerating.\nParameters\ngt_network : BaseSyntheticNetwork A network generated from a generative model. - theta_ratio : float\nPercentage of reporters who exaggerate.\n\nexaggeration_type : str\n(“over”, “under”)\nseed : int\nIf not set, use gt_network.prng instead.\n\nReturns\n\ntheta : numpy.array\nA L x M matrix for theta.\n\n\n\nbuild_self_reporter_mask\ndef build_self_reporter_mask(gt_network):\nBuild the reporters’ mask in a way such that:\n\nA reporter m can report ties in which she is ego: m --&gt; i\nA reporter m can report ties in which she is alter: i --&gt; m\nA reporter m cannot report ties she is not involved, that is i --&gt; j where i != m and j != m\n\nParameters\ngt_network : BaseSyntheticNetwork Generative ground truth model."
  },
  {
    "objectID": "latest/pkg-docs/python.html#classes-1",
    "href": "latest/pkg-docs/python.html#classes-1",
    "title": "📚 Python package documentation",
    "section": "Classes",
    "text": "Classes\n\nBaseSyntheticNetwork\nclass BaseSyntheticNetwork(\n    N: int = 100,\n    M: int = 100,\n    L: int = 1,\n    K: int = 2,\n    seed: int = 0,\n    **kwargs\n):\nA base abstract class for generation and management of synthetic networks. Suitable for representing any type of synthetic network (whether SBM or not).\nParameters\n\nN : int\nNumber of nodes.\nM : int\nNumber of reporters.\nL : int\nNumber of layers.\nK : int\nMaximum edge weight in the adjacency matrix. When K=2, the adjacency matrix will contain some Y_{ij}=0 and Y_{ij}=1.\nseed : int\nPseudo random generator seed to use.\n\n\nAncestors\n\nvimure._io.BaseNetwork\n\n\n\nSubclasses\n\nHollandLaskeyLeinhardtModel\nStandardSBM\n\n\n\n\nDegreeCorrectedSBM\nclass DegreeCorrectedSBM(\n    exp_in: float = 2,\n    exp_out: float = 2.5,\n    **kwargs\n):\nDegree-corrected stochastic blockmodel.\nA generative model that incorporates heterogeneous vertex degrees into stochastic blockmodels, improving the performance of the models for statistical inference of group structure. For more information about this model, see (Karrer and Newman 2011).\nParameters\n\nexp_in : float\nExponent power law of in-degree distribution.\nexp_out : float\nExponent power law of out-degree distribution.\nkwargs : dict\nAdditional arguments of StandardSBM.\n\n\nAncestors\n\nStandardSBM\nBaseSyntheticNetwork\nvimure._io.BaseNetwork\n\n\n\n\nHollandLaskeyLeinhardtModel\nclass HollandLaskeyLeinhardtModel(**kwargs):\nA base abstract class for generation and management of synthetic networks. Suitable for representing any type of synthetic network (whether SBM or not).\nParameters\n\nN : int\nNumber of nodes.\nM : int\nNumber of reporters.\nL : int\nNumber of layers.\nK : int\nMaximum edge weight in the adjacency matrix. When K=2, the adjacency matrix will contain some Y_{ij}=0 and Y_{ij}=1.\nseed : int\nPseudo random generator seed to use.\n\n\nAncestors\n\nBaseSyntheticNetwork\nvimure._io.BaseNetwork\n\n\n\n\nMultitensor\nclass Multitensor(eta=0.5, ExpM=None, **kwargs):\nA generative model with reciprocity\nA mathematically principled generative model for capturing both community and reciprocity patterns in directed networks. Adapted from (Safdari, Contisciani, and De Bacco 2021).\nGenerate a directed, possibly weighted network by using the reciprocity generative model. Can be used to generate benchmarks for networks with reciprocity.\nSteps:\n\nGenerate the latent variables.\nExtract A_{ij} entries (network edges) from a Poisson distribution; its mean depends on the latent variables.\n\nNote: Open Source code available at https://github.com/mcontisc/CRep and modified in accordance with its license.\n\nCopyright (c) 2020 Hadiseh Safdari, Martina Contisciani and Caterina De Bacco.\nParameters\n\neta : float\nInitial value for the reciprocity coefficient. Eta has to be in [0, 1).\nExpM : int\nExpected number of edges\n\nkwargs Additional arguments of StandardSBM\n\nAncestors\n\nStandardSBM\nBaseSyntheticNetwork\nvimure._io.BaseNetwork\n\n\n\n\nStandardSBM\nclass StandardSBM(\n    C: int = 2,\n    structure: str = None,\n    avg_degree: float = 2,\n    sparsify: bool = True,\n    overlapping: float = 0.0,\n    **kwargs\n):\nCreates a standard stochastic block-model synthetic network.\nA generative graph model which assumes the probability of connecting two nodes in a graph is determined entirely by their block assignments. For more information about this model, see Holland, P. W., Laskey, K. B., & Leinhardt, S. (1983). Stochastic blockmodels: First steps. Social networks, 5(2), 109-137. DOI:10.1016/0378-8733(83)90021-7\nParameters\n\nC : int\nNumber of communities\nstructure : str\nStructures for the affinity tensor w. It can be ‘assortative’ or ‘disassortative’.\n\nIt can be a list to map structure for each layer in a multilayer graph. - avg_degree : float\nDesired average degree for the network. It is not guaranteed that the\nultimate network will have that exact average degree value. Try tweaking this parameter if you want to increase or decrease the density of the network. - sparsify : bool\nIf True (default), enforce sparsity.\n\noverlapping : float\nFraction of nodes with mixed membership. It has to be in [0, 1).\n\nkwargs Additional arguments of [StandardSBM](vimure.#vimure.synthetic.StandardSBM)\n\nAncestors\n\nBaseSyntheticNetwork\nvimure._io.BaseNetwork\n\n\n\nSubclasses\n\nDegreeCorrectedSBM\nMultitensor"
  },
  {
    "objectID": "latest/pkg-docs/python.html#functions-1",
    "href": "latest/pkg-docs/python.html#functions-1",
    "title": "📚 Python package documentation",
    "section": "Functions",
    "text": "Functions\n\napply_rho_threshold\ndef apply_rho_threshold(model, threshold=None):\nApply a threshold to binarise the rho matrix and return the recovered Y\n\n\ncalculate_AUC\ndef calculate_AUC(pred, data0, mask=None):\nReturn the AUC of the link prediction. It represents the probability that a randomly chosen missing connection (true positive) is given a higher score by our method than a randomly chosen pair of unconnected vertices (true negative).\nParameters\n\npred : ndarray\nInferred values.\ndata0 : ndarray\nGiven values.\nmask : ndarray\nMask for selecting a subset of the adjacency tensor.\n\nReturns\nAUC value.\n\n\ncalculate_average_over_reporter_mask\ndef calculate_average_over_reporter_mask(X, R):\n\n\ncalculate_overall_reciprocity\ndef calculate_overall_reciprocity(Y):\n\n\nget_item_array_from_subs\ndef get_item_array_from_subs(A, ref_subs):\nGet values of ref_subs entries of a dense tensor. Output is a 1-d array with dimension = number of non zero entries.\n\n\nget_optimal_threshold\ndef get_optimal_threshold(model):\nhttps://arxiv.org/pdf/2112.11396.pdf pg 8\n\n\nis_sparse\ndef is_sparse(X):\nCheck whether the input tensor is sparse. It implements a heuristic definition of sparsity. A tensor is considered sparse if: given M = number of modes S = number of entries I = number of non-zero entries then N &gt; M(I + 1)\nParameters\n\nX : ndarray\nInput data.\n\nReturns\nBoolean flag: true if the input tensor is sparse, false otherwise.\n\n\nmatch_arg\ndef match_arg(x, lst):\n\n\npreprocess\ndef preprocess(X):\nPre-process input data tensor. If the input is sparse, returns an int sptensor. Otherwise, returns an int dtensor.\nParameters\n\nX : ndarray/list\nInput data.\n\nReturns\n\nX : sptensor/dtensor\nPre-processed data. If the input is sparse, returns an int sptensor. Otherwise, returns an int dtensor.\n\n\n\nsparse_max\ndef sparse_max(A, B):\nReturn the element-wise maximum of sparse matrices A and B.\n\n\nsptensor_from_dense_array\ndef sptensor_from_dense_array(X):\nCreate an sptensor from a ndarray or dtensor.\nParameters\n\nX : ndarray\nInput data.\n\nReturns\nsptensor from a ndarray or dtensor.\n\n\nsptensor_from_list\ndef sptensor_from_list(X):\nCreate an sptensor a sptensor from a list.\nAssuming it is a list of dimensions L x M with sparse matrices as elements\n\n\ntranspose_ij\ndef transpose_ij(M):\nCompute the transpose of a matrix.\nParameters\n\nM : numpy.array\nNumpy matrix.\n\nReturns\nTranspose of the matrix."
  },
  {
    "objectID": "latest/tutorials.html",
    "href": "latest/tutorials.html",
    "title": "💻 Tutorials",
    "section": "",
    "text": "Choose your favourite language:\n\n\n  \n\nR\n\n\n\n  \n\nPython"
  },
  {
    "objectID": "latest/tutorials/R-tutorials.html",
    "href": "latest/tutorials/R-tutorials.html",
    "title": "💻 Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n💻 Tutorial 01: Preparing your data for VIMuRe in R\n\n\n25 min\n\n\n\nbasics\n\n\nR\n\n\n\nThis tutorial will show you how to prepare your data for VIMuRe.\n\n\n\n\n\n\n\n\n\n\n💻 Tutorial 02: Introduction to VIMuRe in R\n\n\n26 min\n\n\n\nbasics\n\n\nR\n\n\n\nIf you have network data that is formatted as an edge list, or a set of igraph objects, you can apply VIMuRe model the latent structure of your network.\n\n\n\n\n\n\n\n\n\n\n💻 Tutorial 03: Extracting point estimates from the posterior distribution\n\n\n9 min\n\n\n\nbasics\n\n\nR\n\n\n\nHow to extract point estimates from the posterior distribution of the latent network model fitted using VIMuRe\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you should produce a data frame in the following format:"
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#read-metadata",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#read-metadata",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "3.1. Read metadata",
    "text": "3.1. Read metadata\nLet’s first subset the individual-level metadata to keep only the relevant village:\n# Keep track of where the edgelist files are stored\nRAW_CSV_FOLDER &lt;- \"2010-0760_Data/Data/Raw_csv\"\n\n# Let's focus on just one village for now\nselected_village &lt;- 1\n\n# Filter the individual-level metadata to keep only the relevant village\nresp &lt;- subset(indivinfo, indivinfo$village == selected_village)\nresp$didsurv &lt;- 1\n\n\n\n\n\n\nNote\n\n\n\nThe didsurv column is a dummy variable that indicates whether the individual participated in the survey. We will need this information later to tell our Bayesian model who participated in the survey."
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#read-village-data",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#read-village-data",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "3.2. Read village data",
    "text": "3.2. Read village data\nNow, let’s read the village_1.csv file and merge it with the individual-level metadata:\nvillage_file &lt;- file.path(RAW_CSV_FOLDER, paste(\"village\", selected_village, \".csv\", sep = \"\"))\nindiv &lt;- read.csv(village_file, header = FALSE, as.is = TRUE)\ncolnames(indiv) &lt;- c(\"hhid\", \"ppid\", \"gender\", \"age\")\n\n## gender (1-Male, 2-Female)\nindiv$gender &lt;- dplyr::recode(indiv$gender, \"Male\", \"Female\")\n\n## pre-process pid to match the format in the individual-level metadata\nindiv$pid &lt;- ifelse(nchar(indiv$ppid)==2, paste(indiv$hhid, indiv$ppid, sep = \"\"),\n                    paste(indiv$hhid, 0, indiv$ppid, sep = \"\"))\n\n## Select only the relevant columns\nselected_cols &lt;- c(\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\") \nindiv &lt;- merge(indiv, resp[,selected_cols], by = \"pid\", all.x = TRUE, all.y = TRUE) \nWhich produces a dataframe that looks like this:\nhead(indiv)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npid\nhhid\nppid\ngender\nage\nresp_status\nreligion\ncaste\ndidsurv\n\n\n\n\n100101\n1001\n1\nMale\n75\nNA\nNA\nNA\nNA\n\n\n100102\n1001\n2\nFemale\n55\nNA\nNA\nNA\nNA\n\n\n100103\n1001\n3\nMale\n24\nNA\nNA\nNA\nNA\n\n\n100104\n1001\n4\nFemale\n19\nNA\nNA\nNA\nNA\n\n\n100201\n1002\n1\nMale\n38\n1\n1\n3\n1\n\n\n100202\n1002\n2\nFemale\n27\n2\n1\n3\n1"
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#read-reports-per-relationship-type",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#read-reports-per-relationship-type",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "3.3 Read reports per relationship type",
    "text": "3.3 Read reports per relationship type\nThe survey that produced this data collected information on a number of different types of relationships, four of which were “double sampled” (i.e., asked about in two ways, who people go to for that type of support, and who comes to them). Specifically, they asked about borrowing and receiving money, giving and receiving advice, borrowing and lending household items like kerosene and rice, and visiting and receiving guests. These distinct questions are represented in the data files with the following names:\n\nlendmoney,\nborrowmoney,\ngiveadvice,\nhelpdecision,\nkeroricecome,\nkeroricego,\nvisitcome\nvisitgo\n\nEach of these relationships is stored in a separate file. For example, the file lendmoney1.csv contains information on who reported lending money to whom in village 1.\nWe can read each of these files using the read.csv() function. For example:\nFirst we look over the data and specifying a ALL_NA_CODES variable. This is a vector of all the codes that, after inspection, we identified were used to represent missing values in the data:\nALL_NA_CODES &lt;- c(\"9999999\", \"5555555\", \"7777777\", \"0\")\nWe can then read in the data:\nfilepath_lendmoney &lt;- file.path(RAW_CSV_FOLDER, paste(\"lendmoney\", selected_village, \".csv\", sep=\"\"))\nlendmoney &lt;- read.csv(filepath_lendmoney, header = FALSE, as.is = TRUE, na = ALL_NA_CODES)\nWhat the data look like\nThe data is stored here as a node list, but it will need to be further pre-processed as an edge list:\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\n\n\n\n\n100201\n107603\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n100202\n102902\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n100601\n101901\n102601\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n100602\n100501\n101902\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n100701\n100801\n102101\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n100702\n100801\n104001\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\nEach row represents reports made by a single individual. The numbers in the first column are the pid (the “person identifier”) of the individual who reported the relationship. The remaining however many numbers listed in the same row are the pids of the individuals who were reported to be involved in the relationship."
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#pre-process-the-data-to-build-the-edge-list",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#pre-process-the-data-to-build-the-edge-list",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "3.4. Pre-process the data to build the edge list",
    "text": "3.4. Pre-process the data to build the edge list\nWe want the network data to be in the following format, plus a few additional columns:\n\n\n\n\nego\nalter\n\n\n\n\n100201\n107603\n\n\n100202\n100201\n\n\n100601\n101901\n\n\n100601\n102601\n\n\n100601\n115501\n\n\n100602\n100501\n\n\n100602\n101902\n\n\n100701\n100801\n\n\n100701\n102101\n\n\n100702\n100801\n\n\n\n\nTo achieve this, we will need to pivot the data.\ntie_type &lt;- \"lendmoney\"\n\n# Example with the lendmoney data\nedgelist_lendmoney &lt;- tidyr::pivot_longer(lendmoney, cols=!V1, values_drop_na=TRUE)\n\n# View(edgelist_lendmoney) to see what the data look like\nThis produces a bogus name column, which we can drop. We should also rename the columns to something more meaningful. It is important that we add a respondent column. This will be the pid of the individual who reported the relationship.\nedgelist_lendmoney &lt;- edgelist_lendmoney %&gt;% \n    dplyr::select(-name) %&gt;% \n    rename(ego=V1, alter=value) %&gt;% \n    mutate(reporter=ego)\n\n# Let's also add a column for the tie type\nedgelist_lendmoney$tie_type &lt;- tie_type\n\n# Let's add a weight column too\nedgelist_lendmoney$weight &lt;- 1\nproducing head(edgelist_lendmoney):\n\n\n\n\nego\nalter\nreporter\ntie_type\nweight\n\n\n\n\n100201\n107603\n100201\nlendmoney\n1\n\n\n100202\n102902\n100202\nlendmoney\n1\n\n\n100601\n101901\n100601\nlendmoney\n1\n\n\n100601\n102601\n100601\nlendmoney\n1\n\n\n100602\n100501\n100602\nlendmoney\n1\n\n\n100602\n101902\n100602\nlendmoney\n1\n\n\n\n\nSo far, we only added tie_type = \"lendmoney\" to the data frame, but to make full use of VIMuRe, we also need to add the “flipped question” to the data frame, which in this case is tie_type = \"borrowmoney\". This is because the survey asked two different questions about borrowing and receiving money. The process is the same as before, except that we need to flip the ego and alter columns at the end.\nThere are also some other data cleaning steps that we need to perform: remove self-loops, remove duplicates and keep only reports made by registered reporters. We will do all of that inside a function in the next section, to make it easier to re-use."
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#create-a-function-to-get-the-data-for-a-given-village-and-tie-type",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#create-a-function-to-get-the-data-for-a-given-village-and-tie-type",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "4.1. Create a function to get the data for a given village and tie type",
    "text": "4.1. Create a function to get the data for a given village and tie type\nThis function will also take care of the data cleaning steps that we described in the previous section. Importantly, it will also map the double-sampled tie types to the layer names we will use in VIMuRe.\n\n\nClick here to expand the code for the get_karnataka_survey_data() function\n\nget_karnataka_survey_data &lt;- function(\n                                village_id, \n                                tie_type, \n                                indivinfo,\n                                ties_layer_mapping = list(\n                                    borrowmoney = \"money\",\n                                    lendmoney = \"money\",\n                                    giveadvice = \"advice\",\n                                    helpdecision = \"advice\",\n                                    keroricego = \"kerorice\",\n                                    keroricecome = \"kerorice\",\n                                    visitgo = \"visit\",\n                                    visitcome = \"visit\"\n                                  ),\n                                all_na_codes=c(\"9999999\", \"5555555\", \"7777777\", \"0\"),\n                                raw_csv_folder=RAW_CSV_FOLDER){\n\n  # Filter the individual-level metadata to keep only the relevant village\n  resp &lt;- subset(indivinfo, indivinfo$village == village_id)\n  resp$didsurv &lt;- 1    \n\n  village_file &lt;- file.path(raw_csv_folder, paste(\"village\", village_id, \".csv\", sep = \"\"))\n  metadata &lt;- read.csv(village_file, header = FALSE, as.is = TRUE)\n  colnames(metadata) &lt;- c(\"hhid\", \"ppid\", \"gender\", \"age\")\n\n  ## gender (1-Male, 2-Female)\n  metadata$gender &lt;- dplyr::recode(metadata$gender, \"Male\", \"Female\")\n\n  ## pre-process pid to match the format in the individual-level metadata\n  metadata$pid &lt;- ifelse(nchar(metadata$ppid)==2, paste(metadata$hhid, metadata$ppid, sep = \"\"),\n                         paste(metadata$hhid, 0, metadata$ppid, sep = \"\"))\n\n  ## Select only the relevant columns\n  selected_cols &lt;- c(\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\") \n  metadata &lt;- merge(metadata, resp[,selected_cols], by = \"pid\", all.x = TRUE, all.y = TRUE)\n\n\n  filepath &lt;- file.path(raw_csv_folder, paste(tie_type, village_id, \".csv\", sep=\"\"))\n  df_raw &lt;- read.csv(filepath, header = FALSE, as.is = TRUE, na = all_na_codes)\n\n  edgelist &lt;- tidyr::pivot_longer(df_raw, cols=!V1, values_drop_na=TRUE)\n\n  edgelist &lt;- edgelist %&gt;% \n      dplyr::select(-name) %&gt;% \n      rename(ego=V1, alter=value) %&gt;% \n      mutate(reporter=ego)\n\n  # Let's also add a column for the tie type\n  edgelist$tie_type &lt;- tie_type\n\n  # Let's add a weight column too\n  edgelist$weight &lt;- 1\n\n  # If the question was \"Did you borrow money from anyone?\", then we need to flip the ego and alter columns\n  if(tie_type %in% c(\"borrowmoney\", \"helpdecision\", \"keroricego\", \"visitgo\")){\n    edgelist &lt;- edgelist %&gt;% rename(ego=alter, alter=ego)\n  }\n\n  # Create a layer column and reorder the columns to make it easier to work with VIMuRe later\n  edgelist &lt;- edgelist %&gt;% \n    mutate(layer = unlist(ties_layer_mapping[tie_type])) %&gt;% \n    select(ego, alter, reporter, tie_type, layer, weight)\n\n  #### Further pre-processing steps ####\n\n  # Who could actually report on the ties?\n  reporters &lt;- metadata %&gt;%\n    filter(didsurv == 1) %&gt;%\n    pull(pid) %&gt;%\n    as.vector()\n  nodes &lt;- reporters %&gt;% union(edgelist$ego) %&gt;% union(edgelist$alter)\n\n  # Only keep reports made by those who were MARKED as reporters in metadata CSV\n  edgelist &lt;- edgelist %&gt;% filter(reporter %in% reporters)\n\n  # Remove self-loops\n  edgelist &lt;- edgelist %&gt;% filter(ego != alter)\n\n  # Remove duplicates\n  edgelist &lt;- edgelist %&gt;% distinct()\n\n  return(list(edgelist=edgelist, reporters=reporters))\n\n}\n\nget_indivinfo &lt;- function(metadata_file = DEFAULT_METADATA_FILEPATH){\n    indivinfo &lt;- haven::read_dta(metadata_file)\n    ## one individual (6109803) is repeated twice. Remove the duplicate\n    indivinfo &lt;- indivinfo[!duplicated(indivinfo$pid) == TRUE, ]\n    return(indivinfo)\n}"
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#getting-an-edgelist-per-layer",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#getting-an-edgelist-per-layer",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "4.2 Getting an edgelist per layer",
    "text": "4.2 Getting an edgelist per layer\nEach double-sampled tie type is mapped to a layer in VIMuRe. The mapping can be seen in the function we created above and is also shown below.\nties_layer_mapping = list(borrowmoney = \"money\",\n                          lendmoney = \"money\",\n                          giveadvice = \"advice\",\n                          helpdecision = \"advice\",\n                          keroricego = \"kerorice\",\n                          keroricecome = \"kerorice\",\n                          visitgo = \"visit\",\n                          visitcome = \"visit\")\nTherefore, to get the edgelist for, say the money layer, we need to combine the borrowmoney and lendmoney tie types. We can do this by using the get_karnataka_survey_data function we created above.\n\n# Get the edgelist for the money layer\noutput &lt;- get_karnataka_survey_data(village_id = 1, tie_type = \"lendmoney\", indivinfo = indivinfo)\nedgelist_lendmoney &lt;- output$edgelist\nreporters          &lt;- output$reporters\n\nedgelist_borrowmoney &lt;- get_karnataka_survey_data(village_id = 1, tie_type = \"borrowmoney\", indivinfo = indivinfo)$edgelist\n\nedgelist_money &lt;- rbind(edgelist_lendmoney, edgelist_borrowmoney)\nwhich now gives us all the edges for the money layer:\nset.seed(100) # set the random seed for reproducibility\n\nedgelist_money %&gt;% sample_n(size = 10, replace = FALSE)\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n111903\n111902\n111902\nborrowmoney\nmoney\n1\n\n\n104901\n104101\n104101\nborrowmoney\nmoney\n1\n\n\n111401\n109701\n109701\nborrowmoney\nmoney\n1\n\n\n118001\n112605\n112605\nborrowmoney\nmoney\n1\n\n\n106205\n106302\n106205\nlendmoney\nmoney\n1\n\n\n100701\n100801\n100701\nlendmoney\nmoney\n1\n\n\n111502\n108902\n111502\nlendmoney\nmoney\n1\n\n\n100501\n100801\n100801\nborrowmoney\nmoney\n1\n\n\n112601\n111903\n111903\nborrowmoney\nmoney\n1\n\n\n117301\n109505\n109505\nborrowmoney\nmoney\n1\n\n\n\nThe above is the format we want the data to be in! This format will make it easier to work with VIMuRe. Although, only the ego, alter, reporter columns are required. The tie_type, layer and weight columns are optional, but useful to have.\nUse the full pre-processing script below to pre-process all the data for all tie types and save it to a single vil1_money.csv file. We also save the respondents list to, as a data frame, to a vil1_money_respondents.csv file.\n\n\nClick to see full pre-processing script\n\n# Load the required packages\nlibrary(tidyverse)\n\n# Set the working directory accordingly\n# setwd(\"C:/Users/.../karnataka_survey\")\n\nVALID_VILLAGE_IDS &lt;- c(1:12, 14:21, 23:77) # village IDs 13 and 22 are missing\nRAW_CSV_FOLDER &lt;- \"2010-0760_Data/Data/Raw_csv\"\n\nties_layer_mapping = list(borrowmoney = \"money\",\n                          lendmoney = \"money\",\n                          giveadvice = \"advice\",\n                          helpdecision = \"advice\",\n                          keroricego = \"kerorice\",\n                          keroricecome = \"kerorice\",\n                          visitgo = \"visit\",\n                          visitcome = \"visit\")\n\nget_karnataka_survey_data &lt;- function(\n                                village_id, \n                                tie_type, \n                                indivinfo,\n                                ties_layer_mapping = list(\n                                    borrowmoney = \"money\",\n                                    lendmoney = \"money\",\n                                    giveadvice = \"advice\",\n                                    helpdecision = \"advice\",\n                                    keroricego = \"kerorice\",\n                                    keroricecome = \"kerorice\",\n                                    visitgo = \"visit\",\n                                    visitcome = \"visit\"\n                                  ),\n                                all_na_codes=c(\"9999999\", \"5555555\", \"7777777\", \"0\"),\n                                raw_csv_folder=RAW_CSV_FOLDER){\n\n  # Filter the individual-level metadata to keep only the relevant village\n  resp &lt;- subset(indivinfo, indivinfo$village == village_id)\n  resp$didsurv &lt;- 1    \n\n  village_file &lt;- file.path(raw_csv_folder, paste(\"village\", village_id, \".csv\", sep = \"\"))\n  metadata &lt;- read.csv(village_file, header = FALSE, as.is = TRUE)\n  colnames(metadata) &lt;- c(\"hhid\", \"ppid\", \"gender\", \"age\")\n\n  ## gender (1-Male, 2-Female)\n  metadata$gender &lt;- dplyr::recode(metadata$gender, \"Male\", \"Female\")\n\n  ## pre-process pid to match the format in the individual-level metadata\n  metadata$pid &lt;- ifelse(nchar(metadata$ppid)==2, paste(metadata$hhid, metadata$ppid, sep = \"\"),\n                         paste(metadata$hhid, 0, metadata$ppid, sep = \"\"))\n\n  ## Select only the relevant columns\n  selected_cols &lt;- c(\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\") \n  metadata &lt;- merge(metadata, resp[,selected_cols], by = \"pid\", all.x = TRUE, all.y = TRUE)\n\n\n  filepath &lt;- file.path(raw_csv_folder, paste(tie_type, village_id, \".csv\", sep=\"\"))\n  df_raw &lt;- read.csv(filepath, header = FALSE, as.is = TRUE, na = all_na_codes)\n\n  edgelist &lt;- tidyr::pivot_longer(df_raw, cols=!V1, values_drop_na=TRUE)\n\n  edgelist &lt;- edgelist %&gt;% \n      dplyr::select(-name) %&gt;% \n      rename(ego=V1, alter=value) %&gt;% \n      mutate(reporter=ego)\n\n  # Let's also add a column for the tie type\n  edgelist$tie_type &lt;- tie_type\n\n  # Let's add a weight column too\n  edgelist$weight &lt;- 1\n\n  # If the question was \"Did you borrow money from anyone?\", then we need to flip the ego and alter columns\n  if(tie_type %in% c(\"borrowmoney\", \"helpdecision\", \"keroricego\", \"visitgo\")){\n    edgelist &lt;- edgelist %&gt;% rename(ego=alter, alter=ego)\n  }\n\n  # Create a layer column and reorder the columns to make it easier to work with VIMuRe later\n  edgelist &lt;- edgelist %&gt;% \n    mutate(layer = unlist(ties_layer_mapping[tie_type])) %&gt;% \n    select(ego, alter, reporter, tie_type, layer, weight)\n\n  #### Further pre-processing steps ####\n\n  # Who could actually report on the ties?\n  reporters &lt;- metadata %&gt;%\n    filter(didsurv == 1) %&gt;%\n    pull(pid) %&gt;%\n    as.vector()\n  nodes &lt;- reporters %&gt;% union(edgelist$ego) %&gt;% union(edgelist$alter)\n\n  # Only keep reports made by those who were MARKED as reporters in metadata CSV\n  edgelist &lt;- edgelist %&gt;% filter(reporter %in% reporters)\n\n  # Remove self-loops\n  edgelist &lt;- edgelist %&gt;% filter(ego != alter)\n\n  # Remove duplicates\n  edgelist &lt;- edgelist %&gt;% distinct()\n\n  return(list(edgelist=edgelist, reporters=reporters))\n\n}\n\nget_layer &lt;- function(village_id, layer_name, indivinfo,\n                      raw_csv_folder=RAW_CSV_FOLDER){\n\n  tie_types &lt;- list(\n    money = c(\"borrowmoney\", \"lendmoney\"),\n    advice = c(\"giveadvice\", \"helpdecision\"),\n    kerorice = c(\"keroricego\", \"keroricecome\"),\n    visit = c(\"visitgo\", \"visitcome\")\n  )\n\n  selected_tie_types &lt;- tie_types[[layer_name]]\n\n\n  edgelist &lt;- data.frame()\n  reporters &lt;- c()\n\n  for(tie_type in selected_tie_types){\n    data &lt;- get_karnataka_survey_data(village_id, tie_type, indivinfo, raw_csv_folder=raw_csv_folder)\n    edgelist &lt;- rbind(edgelist, data$edgelist)\n    reporters &lt;- union(reporters, data$reporters)\n  }\n\n  return(list(edgelist=edgelist, reporters=reporters))\n}\n\n\n# Read Stata DTA files\nindivinfo &lt;- haven::read_dta(\"datav4.0/Data/2. Demographics and Outcomes/individual_characteristics.dta\")\nindivinfo &lt;- indivinfo[!duplicated(indivinfo$pid)==TRUE,] ## one individual (6109803) is repeated twice.\n\nfor(i in VALID_VILLAGE_IDS){\n  for(layer_name in c(\"money\", \"advice\", \"kerorice\", \"visit\")){\n    \n    data &lt;- get_layer(i, layer_name, indivinfo, raw_csv_folder=RAW_CSV_FOLDER)\n    edgelist &lt;- data$edgelist\n    reporters &lt;- data$reporters\n\n    # Save the edgelist\n    edgelist_file &lt;- file.path(paste(\"village\", i, \"_\", layer_name, \".csv\", sep = \"\"))\n    write.csv(edgelist, edgelist_file, row.names = FALSE)\n\n    # Save the reporters\n    reporters_file &lt;- file.path(paste(\"village\", i, \"_\", layer_name, \"_reporters.csv\", sep = \"\"))\n    write.csv(data.frame(reporter=reporters), reporters_file, row.names = FALSE)\n\n  }\n}"
  },
  {
    "objectID": "latest/tutorials/R/tutorial01-data-preparation.html#footnotes",
    "href": "latest/tutorials/R/tutorial01-data-preparation.html#footnotes",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that the authors provide a different version of the network data on Harvard Dataverse (Banerjee et al. 2013a). However, we will use the raw version provided by Prof. Jackson in this tutorial, as the version of the Dataverse has already had some pre-processing (importantly, they have made the adjacency matrices symmetric), while the version provided by Prof. Jackson gives the original node list. We will use the Harvard Dataverse files just for the metadata.↩︎"
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you will be able to:\nFound an interesting use case for VIMuRe? Let us know! Open a discussion on our GitHub repository."
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#number-of-nodes",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#number-of-nodes",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "2.1 Number of nodes",
    "text": "2.1 Number of nodes\n\ndata.frameigraph object\n\n\nunique_nodes &lt;- dplyr::union(edgelist$ego, edgelist$alter) %&gt;% unique()\n\ncat(\"Number of nodes:\", length(unique_nodes), \"\\n\")\ncat(\"Number of edges:\", nrow(edgelist), \"\\n\")\nNumber of nodes: 417\nNumber of edges: 2690 \n\n\ncat(\"Number of nodes:\", igraph::vcount(G), \"\\n\")\ncat(\"Number of edges:\", igraph::ecount(G), \"\\n\")\nNumber of nodes: 417\nNumber of edges: 2690"
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#number-of-reporters",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#number-of-reporters",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "2.2 Number of reporters",
    "text": "2.2 Number of reporters\n\ndata.frameigraph object\n\n\nreporters &lt;- edgelist$reporter %&gt;% unique()\ncat(\"Number of reporters: \", length(reporters), \"\\n\")\nNumber of reporters:  203 \n\n\nreporters &lt;- igraph::get.edge.attribute(G, \"reporter\") %&gt;% unique()\ncat(\"Number of reporters: \", length(reporters), \"\\n\")\nNumber of reporters:  203"
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#average-number-of-ties-per-reporter",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#average-number-of-ties-per-reporter",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "2.3: Average number of ties per reporter",
    "text": "2.3: Average number of ties per reporter\nThere are a couple of things to note about this dataset: reporters could name a maximum of four alters for each question, and reporters can only report on ties that they are involved in (e.g., if a reporter is involved, they cannot report on it). Because we are modelling double-sampled questions, each reporter can report a maximum of 8 ties.\nLet’s create a plot to visualise the distribution of the number of ties per reporter:\n\ndata.frameigraph object\n\n\n# Create a plot_df to summarise the number of ties per reporter\n\nplot_df &lt;- edgelist %&gt;%\n  group_by(layer, tie_type, reporter) %&gt;%\n  summarize(n_ties = n(), .groups=\"keep\") %&gt;%\n  ungroup() %&gt;%\n  group_by(n_ties, tie_type, layer) %&gt;%\n  summarize(n_reporters = n(), .groups=\"keep\") %&gt;%\n  ungroup() %&gt;%\n  arrange(layer, n_ties, tie_type)\n\n\n# Create a plot_df to summarise the number of ties per reporter\nplot_df &lt;- data.frame(get.edgelist(G))\ncolnames(plot_df) &lt;- c(\"ego\", \"alter\")\n\nadd_cols &lt;- list.edge.attributes(G)\nfor (i in 1:length(add_cols)) {\n  plot_df[, add_cols[i]] &lt;- get.edge.attribute(G, add_cols[i])\n}\n\nplot_df &lt;- plot_df %&gt;%\n  group_by(layer, tie_type, reporter) %&gt;%\n  summarize(n_ties = n(), .groups=\"keep\") %&gt;%\n  ungroup() %&gt;%\n  group_by(n_ties, tie_type, layer) %&gt;%\n  summarize(n_reporters = n(), .groups=\"keep\") %&gt;%\n  ungroup() %&gt;%\n  arrange(layer, n_ties, tie_type)\n\n\n\nproducing the following table:\n\nLayer adviceLayer keroriceLayer moneyLayer visit\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\ngiveadvice\nadvice\n115\n\n\n1\nhelpdecision\nadvice\n104\n\n\n2\ngiveadvice\nadvice\n45\n\n\n2\nhelpdecision\nadvice\n73\n\n\n3\ngiveadvice\nadvice\n6\n\n\n3\nhelpdecision\nadvice\n13\n\n\n4\ngiveadvice\nadvice\n1\n\n\n4\nhelpdecision\nadvice\n2\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nkeroricecome\nkerorice\n41\n\n\n1\nkeroricego\nkerorice\n42\n\n\n2\nkeroricecome\nkerorice\n99\n\n\n2\nkeroricego\nkerorice\n100\n\n\n3\nkeroricecome\nkerorice\n45\n\n\n3\nkeroricego\nkerorice\n40\n\n\n4\nkeroricecome\nkerorice\n2\n\n\n4\nkeroricego\nkerorice\n4\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nborrowmoney\nmoney\n57\n\n\n1\nlendmoney\nmoney\n66\n\n\n2\nborrowmoney\nmoney\n92\n\n\n2\nlendmoney\nmoney\n86\n\n\n3\nborrowmoney\nmoney\n31\n\n\n3\nlendmoney\nmoney\n16\n\n\n4\nborrowmoney\nmoney\n1\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nvisitcome\nvisit\n45\n\n\n1\nvisitgo\nvisit\n36\n\n\n2\nvisitcome\nvisit\n84\n\n\n2\nvisitgo\nvisit\n67\n\n\n3\nvisitcome\nvisit\n39\n\n\n3\nvisitgo\nvisit\n38\n\n\n4\nvisitcome\nvisit\n11\n\n\n4\nvisitgo\nvisit\n31\n\n\n\n\n\n\n\nAlternatively as a bar plot:\n\n\nClick to show plot code\n\nlibrary(ggplot2)\n\nplot_df$tie_type &lt;- \n  factor(plot_df$tie_type, \n         levels = c(\"visitgo\", \"visitcome\",\n                    \"keroricego\", \"keroricecome\", \n                    \"borrowmoney\", \"lendmoney\",\n                    \"helpdecision\", \"giveadvice\"))\n\nplot_df$layer &lt;- \n  factor(plot_df$layer, \n         levels = c(\"advice\", \"money\", \"kerorice\", \"visit\"))\n\ng = (\n    ggplot(plot_df, aes(x = tie_type, y=n_reporters, fill=layer)) +\n    geom_col() +\n    coord_flip() +\n\n    facet_grid(n_ties ~ ., labeller=label_both) +\n\n    theme_bw() +\n    theme(legend.position = \"bottom\",\n          legend.box.spacing = unit(0.5, \"pt\")) +\n    labs(x = \"Number of ties reported for this prompt\", \n         y = \"Number of reporters\",\n         fill = \"Layer\")\n)\n\nggsave(plot=g, filename=\"tutorial02_fig01.png\", width=6, height=8, dpi=300)\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nNote that the plot above only represents the reports made by the 203 nodes that appear in the reporter column. Given that the total number of nodes in the network is 417, either some nodes did not report on any ties, or they were not interviewed at all.\nVIMuRe will consider all nodes in the network, even if they are not present in the reporter column. If you want to restrict your analysis to include only the network of reporters, you must filter the edge list before proceeding."
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#union-vs.-intersection-and-the-concept-of-concordance",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#union-vs.-intersection-and-the-concept-of-concordance",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "2.4: Union vs. Intersection and the concept of Concordance",
    "text": "2.4: Union vs. Intersection and the concept of Concordance\nConcordance is the proportion of ties in a network that both reporters report. It measures the extent to which the two reporters agree about the tie (see (Ready and Power 2021) for a discussion of concordance in the Karnataka network data). It is calculated as follows:\n\\[\n\\text{Concordance} = \\frac{\\text{\\# of ties reported by both reporters}}{\\text{\\# number of unique ties reported}}\n\\]\n\ndata.frameigraph object\n\n\n# Take the intersection: keep only records where \n# both reporters report on the same tie in both tie_types\ndf_intersection &lt;- \n  edgelist %&gt;% \n  group_by(ego, alter, .drop=FALSE) %&gt;% \n  filter(n() == 2) %&gt;% \n  select(ego, alter) %&gt;%\n  distinct()\n\n# Take the union: keep all ties reported \n# irrespective of tie_type and how many times they were reported\ndf_union &lt;- edgelist %&gt;% select(ego, alter) %&gt;% distinct()\n\n# Concordance\ncat(paste0(\"Concordance is: \", nrow(df_intersection) / nrow(df_union)))\n\n\n# Take the intersection: keep only records where\n# both reporters report on the same tie in both tie_types\nwhich_edges_intersection &lt;- E(G)[count_multiple(G, E(G)) == 2]\n\nG_intersection &lt;- \n  igraph::subgraph.edges(G, which_edges_intersection) %&gt;%\n  igraph::simplify()\n\n# Take the union: keep all ties reported\n# irrespective of tie_type and how many times they were reported\n\nG_union &lt;- igraph::simplify(G)\n\n# Concordance\ncat(\n  paste0(\n    \"Concordance is: \", \n    igraph::ecount(G_intersection) / igraph::ecount(G_union)\n  )\n)\n\n\n\nproducing:\nConcordance is: 0.200226244343891"
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#posterior-estimates",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#posterior-estimates",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "3.1: Posterior Estimates",
    "text": "3.1: Posterior Estimates\nThe four values you get from the get_posterior_estimates() method are the geometric expectations of the distributions of the following parameters:\n\n\n\n\n\n\n\n\nParameter\nSymbol\nDescription\n\n\n\n\nnu\n\\(\\nu\\)\nThe inferred mutuality for the network (latent equivalent to \\(\\eta\\))\n\n\ntheta\n\\(\\theta_{lm}\\)\nThe “reliability” of a reporter \\(m\\) on layer \\(l\\)\n\n\nlambda\n\\(\\lambda_{lk}\\)\nThe latent contribution that \\(Y_l=k\\) has on \\(\\theta_{lm}\\), where \\(k \\in \\{1, \\ldots, K\\}\\) represents the weight of the tie.\n\n\nrho\n\\(\\rho_{lijk}\\)\nThe probability that a directed tie of weight \\(k-1\\) exists between nodes \\(i\\) and \\(j\\) on a particular layer \\(l\\)\n\n\n\nRemember that the expected value of our model is:\n\\[\n\\mathbb{E} \\left[X_{lijm}^{}|Y_{lij}^{} = k\\right] = \\theta_{lm}\\lambda_{lk}^{}+\\eta X_{ljim}^{}\n\\]\nwhere \\(X_{lijm}^{}\\) is the observed value of the tie between nodes \\(i\\) and \\(j\\) reported by reporter \\(m\\) on layer \\(l\\) and \\(Y_{lij}^{}\\) is the “ground truth” of the strength of the directed tie between nodes \\(i\\) and \\(j\\) on layer \\(l\\).\nIn the subsections below, we will provide an explanation of \\(\\nu\\) and \\(\\theta_{lm}\\) parameters and how to reason about the mutuality and “reliability” of reporters. \\(\\rho\\) and \\(\\lambda\\) are more technical and we will go into detail about them in a future tutorial.\nA quick note about \\(\\rho\\)\nIf you want to extract a quick point estimate of the inferred network, you can simply take the expected value of \\(\\rho\\) for \\(k=1\\):\n# Expected value of rho for k=1\nrho = posterior_estimates[['rho']][1,,,2]\nThe code above will return a \\(N \\times N\\) weighted adjacency matrix, which can be thought of as the probability of a tie between individuals \\(i\\) and \\(j\\) on layer \\(l = 0\\) (Tutorial 03 will go into more detail about how to interpret the \\(\\rho\\) parameter.)\nNow let’s look at parameters \\(\\nu\\) and \\(\\theta_{lm}\\):\n\n3.1.1: Mutuality (\\(\\nu\\) or \\(\\eta\\))\nIn our case study:\nposterior_estimates[['nu']]\n0.6289576\nThis indicates a large mutuality in the network. That is, if \\(i\\) reports that \\(j\\) lends money to them, then \\(i\\) is likely to report that \\(j\\) also borrows money from them.\nThis is a network-wide parameter and encompasses all layers. If you have reasons to believe mutuality varies across layers, you have to re-run the model for each layer separately.\n\n\n3.1.2: Under-reporting vs over-reporting: a combination of (\\(\\theta_{lm} \\times \\lambda_{lk}\\))\nFirst, let’s look at the shape of the \\(\\theta\\) array:\ndim(posterior_estimates[['theta']])\n   4 417\nWe have four layers, so the first dimension is 4. The second dimension is the number of reporters in the network. In our case, this shows that VIMuRe infers that there are 417 reporters in the network.\nThis parameter, combined with \\(\\lambda_{lk}\\) represents the “reliability” of a reporter \\(m\\) on layer \\(l\\):\ndim(posterior_estimates[['lambda']])\n 4 2\nThe first dimension is the number of layers \\(l\\), and the second dimension is the strength of the tie, which in this case can assume the values \\(k \\in \\{0, 1\\}\\). We only have two possible values for \\(k\\) because that is the default setting for the VimureModel class. If you want to model more than two possible values for \\(k\\), you can set the K parameter when running the fit function: model.fit(..., K=3).\nThese two parameters combined indicate the probability that a reporter will tend to report ties, in general, for a given layer (recall the expected value of the VIMuRe model shown in Section 3.1: Posterior Estimates). Loosely speaking, we can think of this value as the “reliability” of a reporter on a given layer.\n\n\n\n\n\n\nAnother note on the number of reporters\n\n\n\n\n\nYou might be wondering why there are so many reporters, 417. After all, in Section 2.2: Number of reporters, we calculated this number to be around 200! This is due to a technicality in the way the VIMuRe package handles the data. Our current implementation represents the total number of reporters, \\(M\\) as \\(M = N\\) (i.e. the number of nodes is equal to the number of reporters).\nThis is akin to saying each node has the potential to be a reporter. But to control for which nodes are actually reporters, we use a binary mask, \\(R_{lijm}\\), which is 1 if the node \\(m\\) is a reporter on layer \\(l\\) for the tie between nodes \\(i\\) and \\(j\\) and 0 otherwise. You can control how this mask is built by passing the R parameter to the fit() method. Read more about it in section 3.3: A note on the reporter mask (R).\nChanging this is a priority for the next version of the package. But, as it is not a trivial change, we have decided to leave it as it is for now.\n\n\n\nHow are reporters’ “reliability” distributed across layers?\nLet’s check which reporters have the highest “reliability” values, and plot the values for each layer:\n\n\nClick to see the code\n\n# Get the node mapping: which node corresponds to which index in the array\ndf_nodes &lt;- model$nodeNames\n\n# Which nodes are reporters?\n# Note: this assumes you have a `reporters` list from Tutorial 01\nid_reporters &lt;- df_nodes %&gt;% filter(name %in% reporters) %&gt;% pull(id)\n\ndf_lambda_k1 &lt;- data.frame(\n  layer = model$layerNames,\n  lambda_k1 = posterior_estimates$lambda[,2]\n)\n\ndf_theta_reporters &lt;- purrr::map_dfr(id_reporters, ~ {\n  reporter_id &lt;- .x\n  purrr::map_dfr(seq_along(model$layerNames), ~ {\n    l &lt;- .x\n    layer_name &lt;- model$layerNames[l]\n    theta &lt;- posterior_estimates$theta[l, reporter_id] * df_lambda_k1$lambda_k1[l]\n    reporter_name &lt;- df_nodes$name[reporter_id]\n    tibble(\n      layer = layer_name,\n      reporter_id = reporter_id,\n      reporter_name = reporter_name,\n      theta_scaled = theta\n    )\n  })\n})\n\n\n# Sort by reliability (scaled by lambda_k=1)\ndf_theta_reporters %&gt;%\n  pivot_wider(names_from = layer, values_from = theta_scaled, values_fn = list) %&gt;%\n  select(-1) %&gt;%\n  unnest(cols = everything(), names_repair = \"unique\") %&gt;%\n  arrange(desc(advice), desc(kerorice), desc(money), desc(visit)) %&gt;%\n  head()\n\n\n\nClick to see the code\n\nlibrary(ggplot2)\n\nCOLORS =  c('#E69F25', '#5CB4E4', '#069F72', '#F1E545', '#0773B2', '#CC79A8')\n\ng = (ggplot(df_theta_reporters,  aes(x=theta_scaled, fill=layer)) +\n     geom_histogram(binwidth=0.1, color=\"#212121\") +\n     theme_bw() + \n     facet_grid(layer ~ ., scales=\"free_y\") +\n     scale_fill_manual(values=COLORS, guide=\"none\") +\n     theme(axis.text.x=element_text(size=10),\n           axis.text.y=element_text(size=10),\n           panel.grid.minor=element_blank(),\n           panel.grid.major=element_blank(),           \n           strip.background = element_blank(),\n           strip.text.x = element_text(size=10),\n           axis.title=element_text(size=16)) +\n    scale_x_continuous(name = expression(paste(theta * lambda[k==1])), \n                      breaks = seq(0, 1.1, by = 0.1), \n                      limits = c(0, 1.1)) +\n     scale_y_continuous(name=\"Count\", breaks=seq(0, 60, by=10), limits=c(0, 50)) +\n     ggtitle(expression(paste(\"Reliability distribution across layers (\", theta[{l}], \" \\u00D7 \", lambda[k==1], \")\"))))\n\nggsave(plot=g, filename=\"theta_reporters.png\", width=7, height=9, dpi=300)\n\n\nHow should we interpret the values?\nThe interpretation depends on both the mutuality of the network and the survey design. If the mutuality is high (as indicated by \\(\\nu\\) being closer to 1), reporters will naturally tend to reciprocate the ties they report, by default, thus reporters with high \\(\\theta\\) values (relative to the \\(\\theta\\) distribution) are likely “over-reporting” ties.\nLet’s investigate this a bit further by checking the ties reported by a top reporter (113302) in the advice layer:\n\nReporters ranked by advice “reliability”\n\n\n\n\n\n\n\n\n\n\n\n\n\nreporter_name\nadvice\nkerorice\nmoney\nvisit\n\n\n\n\n113302\n0.8970675\n0.7397009\n0.4591973\n0.2099856\n\n\n113901\n0.8780586\n0.8209907\n0.8680566\n0.6693385\n\n\n109902\n0.8504384\n0.7928275\n0.0000155\n0.6415688\n\n\n109505\n0.8504182\n0.0000130\n0.8384146\n0.8622429\n\n\n105902\n0.8504050\n0.0000128\n0.4580637\n0.3737390\n\n\n105402\n0.8503861\n0.5638047\n0.4760844\n0.7225281\n\n\n\n\n\n\n\nMost reporters have reliability in the \\([0.4, 0.6]\\) interval, but 113302 has a “reliability” of \\(\\approx 0.9\\) in the advice layer. Let’s check the ties reported by this reporter:\nedgelist %&gt;% filter(reporter == \"113302\", layer == \"advice\")\n\nTies reported by 113302 in the layer advice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n113302\n110502\n113302\ngiveadvice\nadvice\n1\n\n\n113302\n113102\n113302\ngiveadvice\nadvice\n1\n\n\n105701\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n110501\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n113601\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n113301\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n\n\n\n\n\nNode 113302 does not report any reciprocal ties, but they do report ties with six other nodes.\nAre all nodes also reporters?\nTwo of these six nodes are not reporters:\nnodes_mentioned &lt;- c(\"110502\", \"113102\", \"105701\", \"110501\", \"113601\", \"113301\")\n\nnot_reporters &lt;- nodes_mentioned %&gt;% setdiff(reporters)\nnot_reporters\n \"113102\" \"105701\"\nWe will never be able to confirm ties between 113302 and these nodes and this is already one of the reasons why 113302’s “reliability” is high. (Note that these two non-reporter nodes will have reliability values of \\(\\approx 0\\)).\nOn top of that, when we look at the reports made by the remaining four reporters, only node 113301 confirms the helpdecision tie reported by 113302:\npotential_friends = c(\"110502\", \"110501\", \"113601\", \"113301\")\n\nedgelist %&gt;% filter(reporter %in% potential_friends & (ego == \"113302\" | alter == \"113302\"))\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n113301\n113302\n113301\ngiveadvice\nadvice\n1\n\n\n\nThat is why 113302’s \\(\\theta\\lambda_{k=1}\\) is high: they report a lot of ties, but only one of them is confirmed by other reporters.\nNodes with values in the average range of the \\(\\theta_{lm}\\lambda_{lk}\\) distribution is likely to be more “reliable” reporters."
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#implicit-assumptions",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#implicit-assumptions",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "3.2: Implicit assumptions",
    "text": "3.2: Implicit assumptions\nYou might have noticed the following warning messages when you ran vimure():\n\nUserWarning: The set of nodes was not informed, using ego and alter columns to infer nodes.\nUserWarning: The set of reporters was not informed, assuming set(reporters) = set(nodes) and N = M.\nUserWarning: Reporters Mask was not informed (parameter R). Parser will build it from reporter column, assuming a reporter can only report their own ties.\n\nThe messages are not errors; they are simply indications that the VIMuRe package has made some implicit assumptions when loading the data. If you would like to set the nodes, and the reporter mask explicitly, you can pass these values as arguments to the fit() method. For example:\nvimure(edgelist, \n       nodes=all_nodes, \n       R=reporter_mask)"
  },
  {
    "objectID": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#a-note-on-the-reporter-mask-r",
    "href": "latest/tutorials/R/tutorial02-introduction-to-vimure.html#a-note-on-the-reporter-mask-r",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in R",
    "section": "3.3: A note on the reporter mask (R)",
    "text": "3.3: A note on the reporter mask (R)\nWhile nodes and reporters are simple lists of strings, the reporter mask R is a multidimensional sparse logical array (a tensor) with dimensions \\(L \\times N \\times N \\times N\\). Here, R[l, i, j, m] indicates that reporter \\(m\\) can report on the tie between \\(i\\) and \\(j\\) if the tie belongs to layer \\(l\\).\nSo, for example, if the survey design was such that reporters could only report on ties involving themselves, this implies:\n\\[\\begin{cases}\n\nR_{lijm} = 1 & \\text{if } i = m \\text{ or } j = m \\\\\nR_{lijm} = 0 & \\text{otherwise}.\n\n\\end{cases}\\]\nDepending on your survey design, you might want to construct R manually. For example, if all reporters were asked about all ties – regardless of whether they were involved in the ties or not – then R would be a multi-dimensional array of ones. We are planning a future tutorial on how to handle different survey designs.\nIt’s worth noting that currently, the last dimension has size \\(N\\) instead of \\(M\\). This is because the current implementation of the code assumes that all reporters are part of the network. The mathematical model, as described in (De Bacco et al. 2023), is more flexible and supports an arbitrary set of reporters, whether they are a subset of nodes or not. However, we have not yet implemented this functionality in the code. Our survey designs have so far assumed that all reporters are part of the network, so this has not been a problem. If this is a feature you would like to see sooner, let us know by adding a discussion on GitHub."
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you will be able to:\nFound an interesting use case for VIMuRe? Let us know! Open a discussion on our GitHub repository."
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html#setup",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html#setup",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "⚙️ Setup",
    "text": "⚙️ Setup\nImport packages\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(reshape2)\n\nlibrary(igraph)\nlibrary(vimure)\n⚠️ Ensure you have installed the latest version of VIMuRe before running this tutorial. Follow the 📦 Installation instructions if you haven’t already."
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html#step-1-ensure-you-have-suitable-data-and-a-fitted-vimure-model",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html#step-1-ensure-you-have-suitable-data-and-a-fitted-vimure-model",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "📥 Step 1: Ensure you have suitable data and a fitted VIMuRe model",
    "text": "📥 Step 1: Ensure you have suitable data and a fitted VIMuRe model\nThis tutorial assumes that you have completed 💻 Tutorial 1 and 💻 Tutorial 02 and that, therefore, you have an edgelist data frame and a fitted model object called model loaded in your Python environment.\nWe have selected a particular village to focus on. The dataset contains information on four different types of relationships: money, advice, visit and kerorice. We stored all the data in a single data frame, edgelist, which looks like this:\nset.seed(100) # for reproducibility\n\nedgelist %&gt;% dplyr::sample_n(size = 10, replace = FALSE)\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n107303\n107307\n107307\nhelpdecision\nadvice\n1\n\n\n116402\n115702\n116402\nkeroricecome\nkerorice\n1\n\n\n103202\n117301\n103202\ngiveadvice\nadvice\n1\n\n\n116201\n110401\n116201\nkeroricecome\nkerorice\n1\n\n\n114606\n109701\n109701\nkeroricego\nkerorice\n1\n\n\n101302\n116201\n101302\nvisitcome\nvisit\n1\n\n\n111204\n110701\n111204\nlendmoney\nmoney\n1\n\n\n108304\n111502\n108304\nkeroricecome\nkerorice\n1\n\n\n117301\n113901\n113901\nborrowmoney\nmoney\n1\n\n\n106201\n116105\n106201\nkeroricecome\nkerorice\n1\n\n\n\nWe then ran VIMuRe on this data frame to fit a latent network model:\nlibrary(vimure)\n\n# Run the model\nmodel &lt;- vimure(edgelist)\nIf you have both objects in your environment, you are ready to go!"
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html#step-2-interpreting-the-variable-rho",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html#step-2-interpreting-the-variable-rho",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "📊 Step 2: Interpreting the variable \\(\\rho\\)",
    "text": "📊 Step 2: Interpreting the variable \\(\\rho\\)\nIn this step, our main focus is to analyze the posterior distribution of the latent variable known as rho, which is included in the list of posterior estimates of the model.\nrho = posterior_estimates &lt;- model$get_posterior_estimates()$rho\n\ndim(rho)\n4 417 417   2\nThe variable rho is represented as a tensor with dimensions L x N x N x K. Each entry in the tensor can be denoted as \\(\\rho_{lijk}\\), which corresponds to the geometric expectations of the probability of a directed tie with weight \\(k-1\\) existing between nodes \\(i\\) and \\(j\\) on a specific layer \\(l\\).\n\nA note about the parameter \\(K\\)\nThe final dimension of the tensor, denoted by \\(K\\), represents the strength of a tie. By default, the model assumes that the interest is in the presence or absence of ties rather than their weight, resulting in a default value of \\(K=2\\). Consequently, for each potential edge, there are two values of \\(\\rho\\): \\(\\rho_{lijk=1}\\) and \\(\\rho_{lijk=2}\\), corresponding to edges with weights 0 and 1 (\\(k-1\\)) respectively.\nTo make this clearer, let’s consider a specific example. Suppose we want to determine the probability of a directed tie with weight 1 existing between nodes 10 and 15 on layer 1 (‘advice’) of our network. We can examine the following entry in the tensor:\n# rho for layer 1, ego 10, alter 15\nrho[1, 11, 16, ] \nThe result would be:\n[1] 1.000000e+00 4.135746e-13\nThis suggests that the model assigns a high probability (approximately 100%) to the absence of a directed tie between nodes 10 and 15 on layer 1 (\\(\\rho_{lijk=1} \\approx 1\\)). Conversely, it assigns a low probability (approximately 0%) to the presence of a directed tie between nodes 10 and 15 on layer 1 (\\(\\rho_{lijk=2} \\approx 0\\)). Based on this, we can conclude that node 10 does not provide advice to node 15.\nIf you are modelling weighted networks, you can specify a different value for \\(K\\), as shown below. Just note that K must be an integer.\n# Fit the model with a different value for K\n\nmodel &lt;- vimure(edgelist, K=10)\n\n\nVisualising rho\nSince the probability of \\(K=1\\) and \\(K=2\\) are complementary, we can plot the probability of a directed tie existing between nodes \\(i\\) and \\(j\\) on layer \\(l\\) as a function of \\(\\rho_{lijk=2}\\). But before we proceed to the plot, let’s take a look at the summary statistics of the values of \\(\\rho\\) per layer:\n\n\nShow code\n\n# The code below extracts the values of rho for k=2 \n# and calculates summary statistics for each layer\napply(rho[,,,2], 1, function(mat){summary(c(mat))})\n\n                [,1]         [,2]         [,3]         [,4]\nMin.    1.422001e-13 1.543201e-13 1.459111e-13 1.438627e-13\n1st Qu. 3.610989e-13 5.066806e-13 4.103419e-13 4.457248e-13\nMedian  4.647597e-13 7.397324e-13 6.378388e-13 6.876110e-13\nMean    2.119759e-03 2.324725e-03 2.187926e-03 2.538284e-03\n3rd Qu. 6.281224e-13 8.889993e-13 8.399095e-13 8.608209e-13\nMax.    1.000000e+00 9.998318e-01 9.998739e-01 1.000000e+00\nThe expected values of \\(\\rho\\) are very small, with a very narrow interquartile range and a mean of approximately 0.002. Observe how the minimum value is close but never truly zero, which is a consequence of the Bayesian approach. The inferred network is sparse, as can be expected from a social network of this type.\nLet’s look at how the values of \\(\\rho\\) are distributed across layers. We can do this by plotting the distribution of \\(\\rho_{lijk=2}\\) for each layer:\n\n\nShow code\n\n# Create a data frame with the values of rho for k=2\nrho_df &lt;- reshape2::melt(rho[,,,2]) %&gt;% \n    setNames(c(\"Layer\", \"Ego\", \"Alter\", \"Value\")) %&gt;%\n    mutate(Layer = factor(Layer, labels = model$layerNames))\n\n# Plot the distribution of rho for k=2\ng &lt;- ggplot(rho_df, aes(x = Ego, y = Alter, fill = Value)) +\n    geom_tile() +\n    facet_wrap(~ Layer, labeller = label_both) +\n    scale_fill_gradient(low = \"#f7fbff\", high = \"blue\", name = expression(rho), limits=c(0,1)) +\n    labs(x = \"Ego\", y = \"Alter\", title = expression(paste(\"Distribution of \", rho[{lijk==2}]))) +\n    theme_bw() +\n    theme(axis.text=element_text(size=rel(1.5)),\n          legend.text=element_text(size=rel(1.3)),\n          legend.title=element_text(size=rel(1.3)),\n          strip.text=element_text(size=rel(1.5)),\n          plot.background = element_rect(fill = \"transparent\", colour = NA),\n          panel.grid.minor = element_blank(),\n          panel.grid.major = element_blank())\n\n\n\n\nFigure 1. Distribution of \\(\\rho_{lijk=2}\\)\n\n\nThe plots above give us an idea of how sparse the network is, but without any meaningful node ordering, it’s hard to see its structure. In the next section, we’ll use \\(\\rho_{lijk=2}\\) as a measure of edge strength and treat it as a point estimate for our model. This will help us get a clearer picture of this multi-layered network."
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html#step-3-obtaining-a-simple-point-estimate",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html#step-3-obtaining-a-simple-point-estimate",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "🎲 Step 3: Obtaining a simple point estimate",
    "text": "🎲 Step 3: Obtaining a simple point estimate\nWe can treat the probability values represented by \\(\\rho_{lijk=2}\\) directly as a point estimate, but since most of the entries are very small and none of them are zero, this would lead to a dense network. Instead, it might be more appropriate to apply a thresholding approach and set lower values to zero.\nHowever, determining the appropriate threshold value \\(t_{\\rho}\\) is not as straightforward as it initially seems. While a suggestion of setting \\(t_{\\rho}=0.5\\) may arise based on the assumption of complementarity between \\(\\rho_{lijk=2}\\) and \\(\\rho_{lijk=1}\\), our research paper (De Bacco et al. 2023, 10–11) reveals the need for adjusting the threshold based on the inferred mutuality, \\(\\eta_{est}\\) (represented by the latent variable \\(\\nu\\)), to achieve a similar level of reciprocity — a network property of interest — as observed in the ground truth network. In other words, tailoring the threshold becomes necessary to ensure that the inferred network accurately captures the desired network property.\nIn the paper, we found that the threshold \\(t_{\\rho}\\) should be set to \\(t_{\\rho} = 0.33 \\times \\eta_{est} + 0.10\\) was a good heuristic to capture reciprocity in simulated synthetic networks with reciprocity. Let’s use this same value here to obtain a point estimate of our network:\nthreshold &lt;- 0.33 * model$get_posterior_estimates()$nu + 0.10\nthreshold\n0.3075572\nWe can then apply the threshold to the values of \\(\\rho_{lijk=2}\\) to obtain a point estimate of the network:\n# Apply the threshold\nrho_point_estimate &lt;- rho[,,,2] &gt; threshold\nTo get the network to look consistent across layers, let’s create a layout from the union of all nodes and edges across layers:\nigraph::graph_from_adjacency_matrix(apply(rho_point_estimate, 2:3, sum) &gt; 0) %&gt;%\n    igraph::layout_with_fr() -&gt; layout\n\ndim(layout)\n417 2\nFinally, we can plot the network using the layout and the thresholded values of \\(\\rho_{lijk=2}\\):\n\n\nShow code\n\n# Load the igraph library\nlibrary(igraph)\n\n# Create a list of graphs from the rho point estimate\nnum_layers &lt;- dim(rho_point_estimate)[1]\ngs &lt;- lapply(1:num_layers, function(l) {\n  graph_from_adjacency_matrix(as.matrix(rho_point_estimate[l,,]), mode = \"directed\")\n})\n\nmax_degree &lt;- max(sapply(gs, function(g) max(degree(g))))\n\n# Create a 2 x 2 plot layout\npar(mfrow = c(2,2))\n\n# Loop over the layers\nfor (l in 1:num_layers) {\n  g &lt;- gs[[l]]\n  degree &lt;- degree(g)\n  # Scale degree to the interval [4 - 12]\n  degree &lt;- degree / max(degree) * 7 + 1\n  plot(g, \n       vertex.size = degree, \n       vertex.label=NA,\n       edge.width = 0.6,\n       edge.arrow.size = 0.1,\n       opacity=0.7,\n       layout=layout,\n       main = paste(\"Layer:\", model$layerNames[l]))\n}\n\n\n\n\nFigure 2. A point estimate of the four layers of the network, obtained by thresholding \\(\\rho_{lijk=2}\\). Node sizes are scaled according to their degree in the network layer."
  },
  {
    "objectID": "latest/tutorials/R/tutorial03-the-posterior.html#next-steps",
    "href": "latest/tutorials/R/tutorial03-the-posterior.html#next-steps",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "Next steps",
    "text": "Next steps\n🚧 TODO: Which network properties can we infer from the networks obtained above?\n🚧 TODO: How does that compare to \\(t_{\\rho}=0.5\\)?"
  },
  {
    "objectID": "latest/tutorials/python-tutorials.html",
    "href": "latest/tutorials/python-tutorials.html",
    "title": "💻 Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n💻 Tutorial 01: Preparing your data for VIMuRe in python\n\n\n26 min\n\n\n\nbasics\n\n\npython\n\n\n\nThis tutorial will show you how to prepare your data for VIMuRe.\n\n\n\n\n\n\n\n\n\n\n💻 Tutorial 02: Introduction to VIMuRe in Python\n\n\n27 min\n\n\n\nbasics\n\n\npython\n\n\n\nIf you have network data that is formatted as an edge list, or a set of igraph objects, you can apply VIMuRe model the latent structure of your network.\n\n\n\n\n\n\n\n\n\n\n💻 Tutorial 03: Extracting point estimates from the posterior distribution\n\n\n10 min\n\n\n\nbasics\n\n\npython\n\n\n\nHow to extract point estimates from the posterior distribution of the latent network model fitted using VIMuRe\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you should produce a data frame in the following format:"
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#read-metadata",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#read-metadata",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "3.1. Read metadata",
    "text": "3.1. Read metadata\nLet’s first subset the individual-level metadata to keep only the relevant village:\n# Keep track of where the edgelist files are stored\nRAW_CSV_FOLDER = \"2010-0760_Data/Data/Raw_csv\"\n\n# Let's focus on just one village for now\nselected_village = 1\n\n# Filter the individual-level metadata to keep only the relevant village\nresp = indivinfo[indivinfo[\"village\"] == 1].copy()\nresp[\"didsurv\"] = 1\n\n\n\n\n\n\nNote\n\n\n\nThe didsurv column is a dummy variable that indicates whether the individual participated in the survey. We will need this information later to tell our Bayesian model who participated in the survey."
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#read-village-data",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#read-village-data",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "3.2. Read village data",
    "text": "3.2. Read village data\nNow, let’s read the village_1.csv file and merge it with the individual-level metadata:\nvillage_file = os.path.join(RAW_CSV_FOLDER, f\"village{selected_village}.csv\")\nindiv = pd.read_csv(village_file, header = None, names=[\"hhid\", \"ppid\", \"gender\", \"age\"])\n\n## gender (1-Male, 2-Female)\nindiv[\"gender\"] = indiv[\"gender\"].map({1: \"Male\", 2: \"Female\"})\n\n## pre-process pid to match the format in the individual-level metadata\nindiv[\"ppid\"] = indiv[\"ppid\"].astype(str)\nindiv[\"hhid\"] = indiv[\"hhid\"].astype(str)\nindiv[\"pid\"] =  indiv.apply(lambda x: f'{x[\"hhid\"]}{0 if len(x[\"ppid\"]) != 2 else \"\"}{x[\"ppid\"]}', axis=1)\n\n## Select only the relevant columns\nselected_cols = [\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\"]\nindiv = pd.merge(indiv, resp[selected_cols], on=\"pid\", how=\"left\")\nWhich produces a dataframe that looks like this:\nindiv.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhhid\nppid\ngender\nage\npid\nresp_status\nreligion\ncaste\ndidsurv\n\n\n\n\n0\n1001\n1\nMale\n75\n100101\nnan\nnan\nnan\nnan\n\n\n1\n1001\n2\nFemale\n55\n100102\nnan\nnan\nnan\nnan\n\n\n2\n1001\n3\nMale\n24\n100103\nnan\nnan\nnan\nnan\n\n\n3\n1001\n4\nFemale\n19\n100104\nnan\nnan\nnan\nnan\n\n\n4\n1002\n1\nMale\n38\n100201\nHead of Household\nHINDUISM\nOBC\n1"
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#read-reports-per-relationship-type",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#read-reports-per-relationship-type",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "3.3 Read reports per relationship type",
    "text": "3.3 Read reports per relationship type\nThe survey that produced this data collected information on a number of different types of relationships, four of which were “double sampled” (i.e., asked about in two ways, who people go to for that type of support, and who comes to them). Specifically, they asked about borrowing and receiving money, giving and receiving advice, borrowing and lending household items like kerosene and rice, and visiting and receiving guests. These distinct questions are represented in the data files with the following names:\n\nlendmoney,\nborrowmoney,\ngiveadvice,\nhelpdecision,\nkeroricecome,\nkeroricego,\nvisitcome\nvisitgo\n\nEach of these relationships is stored in a separate file. For example, the file lendmoney1.csv contains information on who reported lending money to whom in village 1. We can read each of these files using the pd.read_csv() function.\nFirst, we look over the data and specify an ALL_NA_CODES variable. This is a vector of all the codes that, after inspection, we identified were used to represent missing values in the data:\nALL_NA_CODES = [\"9999999\", \"5555555\", \"7777777\", \"0\"]\nWe can then read in the data:\nfilepath_lendmoney = os.path.join(RAW_CSV_FOLDER, f\"lendmoney{selected_village}.csv\")\nlendmoney = pd.read_csv(filepath_lendmoney, header=None, na_values=ALL_NA_CODES, dtype=str)\nWhat the data look like\nThe data is stored here as a node list, but it will need to be further pre-processed as an edge list:\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n100201\n107603\nnan\nnan\nnan\nnan\nnan\nnan\nnan\n\n\n100202\n102902\nnan\nnan\nnan\nnan\nnan\nnan\nnan\n\n\n100601\n101901\n102601\nnan\nnan\nnan\nnan\nnan\nnan\n\n\n100602\n100501\n101902\nnan\nnan\nnan\nnan\nnan\nnan\n\n\n100701\n100801\n102101\nnan\nnan\nnan\nnan\nnan\nnan\n\n\n\n\nEach row represents reports made by a single individual. The numbers in the first column are the pid (the “person identifier”) of the individual who reported the relationship. The remaining however many numbers listed in the same row are the pids of the individuals who were reported to be involved in the relationship."
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#pre-process-the-data-to-build-the-edge-list",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#pre-process-the-data-to-build-the-edge-list",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "3.4. Pre-process the data to build the edge list",
    "text": "3.4. Pre-process the data to build the edge list\nWe want the network data to be in the following format, plus a few additional columns:\n\n\n\n\nego\nalter\n\n\n\n\n100201\n107603\n\n\n100202\n100201\n\n\n100601\n101901\n\n\n100601\n102601\n\n\n100601\n115501\n\n\n100602\n100501\n\n\n100602\n101902\n\n\n100701\n100801\n\n\n100701\n102101\n\n\n100702\n100801\n\n\n\n\nTo achieve this, we will need to pivot the data.\ntie_type = \"lendmoney\"\n\n# Example with the lendmoney data\nedgelist_lendmoney = pd.melt(lendmoney, id_vars=[0]).dropna()\nThis produces a bogus variable column, which we can drop. We should also rename the columns to something more meaningful. It is important that we add a reporter column. This will be the pid of the individual who reported the relationship.\nedgelist_lendmoney = edgelist_lendmoney.drop(columns=\"variable\")\\\n       .rename(columns={0: \"ego\", \"value\": \"alter\"})\\\n       .assign(reporter=lambda x: x[\"ego\"])\n\n# Let's also add a column for the tie type\nedgelist_lendmoney = edgelist_lendmoney.assign(tie_type=tie_type)\n\n# Let's add a weight column too\nedgelist_lendmoney = edgelist_lendmoney.assign(weight=1)\nproducing edgelist_lendmoney.head():\n\n\n\n\nego\nalter\nreporter\ntie_type\nweight\n\n\n\n\n100201\n107603\n100201\nlendmoney\n1\n\n\n100202\n102902\n100202\nlendmoney\n1\n\n\n100601\n101901\n100601\nlendmoney\n1\n\n\n100602\n100501\n100602\nlendmoney\n1\n\n\n100701\n100801\n100701\nlendmoney\n1\n\n\n\n\nSo far, we only added tie_type = \"lendmoney\" to the data frame, but to make full use of VIMuRe, we also need to add the “flipped question” to the data frame, which in this case is tie_type = \"borrowmoney\". This is because the survey asked two different questions about borrowing and receiving money. The process is the same as before, except that we need to flip the ego and alter columns at the end.\nThere are also some other data cleaning steps that we need to perform: remove self-loops, remove duplicates and keep only reports made by registered reporters. We will do all of that inside a function in the next section, to make it easier to re-use."
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#create-a-function-to-get-the-data-for-a-given-village-and-tie-type",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#create-a-function-to-get-the-data-for-a-given-village-and-tie-type",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "4.1. Create a function to get the data for a given village and tie type",
    "text": "4.1. Create a function to get the data for a given village and tie type\nThis function will also take care of the data cleaning steps that we described in the previous section. Importantly, it will also map the double-sampled tie types to the layer names we will use in VIMuRe.\n\n\nClick here to expand the code for the get_karnataka_survey_data() function\n\ndef get_karnataka_survey_data(village_id: int, tie_type: str,\n                              indivinfo: pd.DataFrame,\n                              ties_layer_mapping={\n                                  \"borrowmoney\": \"money\",\n                                  \"lendmoney\": \"money\",\n                                  \"giveadvice\": \"advice\",\n                                  \"helpdecision\": \"advice\",\n                                  \"keroricego\": \"kerorice\",\n                                  \"keroricecome\": \"kerorice\",\n                                  \"visitgo\": \"visit\",\n                                  \"visitcome\": \"visit\",\n                              },\n                              all_na_codes=[\"9999999\", \"5555555\", \"7777777\", \"0\"],\n                              raw_csv_folder=RAW_CSV_FOLDER):\n    \"\"\"\n    Read the raw data for a given tie type and village id, \n    and return two dataframes: the edgelist and the list of respondents.\n\n    Parameters\n    ----------\n    village_id : int\n        The village id, between 1 and 10.\n    tie_type : str\n        The tie type\n    indivinfo : pd.DataFrame\n        The individual-level metadata\n    all_na_codes : list, optional\n        The list of codes that should be interpreted as missing values, by default [\"9999999\", \"5555555\", \"7777777\", \"0\"]\n    raw_csv_folder : str, optional\n        The path to the folder containing the raw csv files, by default \"2010-0760_Data/Data/Raw_csv\"\n\n    Returns\n    -------\n\n    edgelist : pd.DataFrame\n        The edgelist\n\n    respondents : list\n        The respondent metadata\n\n    \"\"\"\n\n    # Filter the individual-level metadata to keep only the relevant village\n    resp = indivinfo[indivinfo[\"village\"] == village_id].copy()\n    resp[\"didsurv\"] = 1\n\n    village_file = os.path.join(raw_csv_folder, f\"village{village_id}.csv\")\n    metadata = pd.read_csv(village_file, header = None, names=[\"hhid\", \"ppid\", \"gender\", \"age\"])\n\n    ## gender (1-Male, 2-Female)\n    metadata[\"gender\"] = metadata[\"gender\"].map({1: \"Male\", 2: \"Female\"})\n\n    ## pre-process pid to match the format in the individual-level metadata\n    metadata[\"ppid\"] = metadata[\"ppid\"].astype(str)\n    metadata[\"hhid\"] = metadata[\"hhid\"].astype(str)\n    metadata[\"pid\"] =  metadata.apply(lambda x: f'{x[\"hhid\"]}{0 if len(x[\"ppid\"]) != 2 else \"\"}{x[\"ppid\"]}', axis=1)\n\n    ## Select only the relevant columns\n    selected_cols = [\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\"]\n    metadata = pd.merge(metadata, resp[selected_cols], on=\"pid\", how=\"left\")\n\n    # Read the raw data\n    filepath = os.path.join(raw_csv_folder, f\"{tie_type}{village_id}.csv\")\n    df_raw = pd.read_csv(filepath, header=None, na_values=all_na_codes, dtype=str)\n\n    # Example with the data\n    edgelist = pd.melt(df_raw, id_vars=[0]).dropna()\n\n    edgelist = edgelist.drop(columns=\"variable\")\\\n          .rename(columns={0: \"ego\", \"value\": \"alter\"})\\\n          .assign(reporter=lambda x: x[\"ego\"])\n\n    # Let's also add a column for the tie type\n    edgelist = edgelist.assign(tie_type=tie_type)\n\n    # Let's add a weight column too\n    edgelist = edgelist.assign(weight=1)\n\n    # If the question was \"Did you borrow money from anyone?\", then we need to flip the ego and alter columns\n    if tie_type in [\"borrowmoney\", \"helpdecision\", \"keroricego\", \"visitgo\"]:\n        edgelist = edgelist.rename(columns={\"ego\": \"alter\", \"alter\": \"ego\"})\n\n    edgelist[\"layer\"] = edgelist[\"tie_type\"].map(ties_layer_mapping)\n\n    # Reorder the columns to make it easier to read\n    edgelist = edgelist[[\"ego\", \"alter\", \"reporter\", \"tie_type\", \"layer\", \"weight\"]]\n\n    #### Further pre-processing steps ####\n\n    # Who could actually report on the ties?\n    reporters = set(metadata[metadata[\"didsurv\"] == 1][\"pid\"])\n    nodes = reporters.union(set(edgelist[\"ego\"])).union(set(edgelist[\"alter\"]))\n\n    # Only keep reports made by those who were MARKED as reporters in metadata CSV\n    edgelist = edgelist[edgelist[\"reporter\"].isin(reporters)].copy()\n\n    # Remove self-loops\n    edgelist = edgelist[edgelist[\"ego\"] != edgelist[\"alter\"]].copy()\n\n    # Remove duplicates\n    edgelist.drop_duplicates(inplace=True)\n\n    return edgelist, reporters"
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#getting-an-edgelist-per-layer",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#getting-an-edgelist-per-layer",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "4.2 Getting an edgelist per layer",
    "text": "4.2 Getting an edgelist per layer\nEach double-sampled tie type is mapped to a layer in VIMuRe. The mapping can be seen in the function we created above and is also shown below.\nties_layer_mapping={\n    \"borrowmoney\": \"money\",\n    \"lendmoney\": \"money\",\n    \"giveadvice\": \"advice\",\n    \"helpdecision\": \"advice\",\n    \"keroricego\": \"kerorice\",\n    \"keroricecome\": \"kerorice\",\n    \"visitgo\": \"visit\",\n    \"visitcome\": \"visit\",\n}\nTherefore, to get the edgelist for, say the money layer, we need to combine the borrowmoney and lendmoney tie types. We can do this by using the get_karnataka_survey_data function we created above.\n\n# Get the edgelist for the money layer\nedgelist_lendmoney, respondents =\\\n  get_karnataka_survey_data(village_id=1, tie_type=\"lendmoney\", indivinfo=indivinfo)\n\nedgelist_borrowmoney, _ = \\\n  get_karnataka_survey_data(village_id=1, tie_type=\"borrowmoney\", indivinfo=indivinfo)\n\nedgelist_money = pd.concat([edgelist_lendmoney, edgelist_borrowmoney], axis=0)\nwhich now gives us all the edges for the money layer:\nedgelist_money.sample(n=10, random_state=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n235\n103101\n103201\n103201\nborrowmoney\nmoney\n1\n\n\n229\n101201\n102901\n102901\nborrowmoney\nmoney\n1\n\n\n130\n111904\n112602\n111904\nlendmoney\nmoney\n1\n\n\n40\n113201\n104001\n104001\nborrowmoney\nmoney\n1\n\n\n14\n101303\n115704\n101303\nlendmoney\nmoney\n1\n\n\n345\n112901\n113601\n113601\nborrowmoney\nmoney\n1\n\n\n50\n104801\n104901\n104901\nborrowmoney\nmoney\n1\n\n\n97\n108803\n107503\n108803\nlendmoney\nmoney\n1\n\n\n241\n102901\n103701\n103701\nborrowmoney\nmoney\n1\n\n\n198\n117202\n115504\n117202\nlendmoney\nmoney\n1\n\n\n\n\nThe above is the format we want the data to be in! This format will make it easier to work with VIMuRe. Although, only the ego, alter, reporter columns are required. The tie_type, layer and weight columns are optional, but useful to have.\nUse the full pre-processing script below to pre-process all the data for all tie types and save it to a single vil1_money.csv file. We also save the reporters list to, as a data frame, to a vil1_money_reporters.csv file.\n\n\nClick to see full pre-processing script\n\nimport os\nimport pandas as pd\n\n# village IDs 13 and 22 are missing\nVALID_VILLAGE_IDS = [i for i in range(1, 77+1) if i != 13 and i != 22] \n\nRAW_CSV_FOLDER = \"2010-0760_Data/Data/Raw_csv\"\n\nties_layer_mapping={\n    \"borrowmoney\": \"money\",\n    \"lendmoney\": \"money\",\n    \"giveadvice\": \"advice\",\n    \"helpdecision\": \"advice\",\n    \"keroricego\": \"kerorice\",\n    \"keroricecome\": \"kerorice\",\n    \"visitgo\": \"visit\",\n    \"visitcome\": \"visit\",\n}\n\ndef get_karnataka_survey_data(village_id: int, tie_type: str,\n                              indivinfo: pd.DataFrame,\n                              ties_layer_mapping=ties_layer_mapping,\n                              all_na_codes=[\"9999999\", \"5555555\", \"7777777\", \"0\"],\n                              raw_csv_folder=RAW_CSV_FOLDER):\n    \"\"\"\n    Read the raw data for a given tie type and village id, \n    and return two dataframes: the edgelist and the list of respondents.\n\n    Parameters\n    ----------\n    village_id : int\n        The village id, between 1 and 10.\n    tie_type : str\n        The tie type\n    indivinfo : pd.DataFrame\n        The individual-level metadata\n    all_na_codes : list, optional\n        The list of codes that should be interpreted as missing values, by default [\"9999999\", \"5555555\", \"7777777\", \"0\"]\n    raw_csv_folder : str, optional\n        The path to the folder containing the raw csv files, by default \"2010-0760_Data/Data/Raw_csv\"\n\n    Returns\n    -------\n\n    edgelist : pd.DataFrame\n        The edgelist\n\n    respondents : list\n        The respondent metadata\n\n    \"\"\"\n\n    # Filter the individual-level metadata to keep only the relevant village\n    resp = indivinfo[indivinfo[\"village\"] == village_id].copy()\n    resp[\"didsurv\"] = 1\n\n    village_file = os.path.join(raw_csv_folder, f\"village{village_id}.csv\")\n    metadata = pd.read_csv(village_file, header = None, names=[\"hhid\", \"ppid\", \"gender\", \"age\"])\n\n    ## gender (1-Male, 2-Female)\n    metadata[\"gender\"] = metadata[\"gender\"].map({1: \"Male\", 2: \"Female\"})\n\n    ## pre-process pid to match the format in the individual-level metadata\n    metadata[\"ppid\"] = metadata[\"ppid\"].astype(str)\n    metadata[\"hhid\"] = metadata[\"hhid\"].astype(str)\n    metadata[\"pid\"] =  metadata.apply(lambda x: f'{x[\"hhid\"]}{0 if len(x[\"ppid\"]) != 2 else \"\"}{x[\"ppid\"]}', axis=1)\n\n    ## Select only the relevant columns\n    selected_cols = [\"pid\", \"resp_status\", \"religion\", \"caste\", \"didsurv\"]\n    metadata = pd.merge(metadata, resp[selected_cols], on=\"pid\", how=\"left\")\n\n    # Read the raw data\n    filepath = os.path.join(raw_csv_folder, f\"{tie_type}{village_id}.csv\")\n    df_raw = pd.read_csv(filepath, header=None, na_values=all_na_codes, dtype=str)\n\n    # Example with the data\n    edgelist = pd.melt(df_raw, id_vars=[0]).dropna()\n\n    edgelist = edgelist.drop(columns=\"variable\")\\\n          .rename(columns={0: \"ego\", \"value\": \"alter\"})\\\n          .assign(reporter=lambda x: x[\"ego\"])\n\n    # Let's also add a column for the tie type\n    edgelist = edgelist.assign(tie_type=tie_type)\n\n    # Let's add a weight column too\n    edgelist = edgelist.assign(weight=1)\n\n    # If the question was \"Did you borrow money from anyone?\", then we need to flip the ego and alter columns\n    if tie_type in [\"borrowmoney\", \"helpdecision\", \"keroricego\", \"visitgo\"]:\n        edgelist = edgelist.rename(columns={\"ego\": \"alter\", \"alter\": \"ego\"})\n\n    edgelist[\"layer\"] = edgelist[\"tie_type\"].map(ties_layer_mapping)\n\n    # Reorder the columns to make it easier to read\n    edgelist = edgelist[[\"ego\", \"alter\", \"reporter\", \"tie_type\", \"layer\", \"weight\"]]\n\n    #### Further pre-processing steps ####\n\n    # Who could actually report on the ties?\n    reporters = set(metadata[metadata[\"didsurv\"] == 1][\"pid\"])\n    nodes = reporters.union(set(edgelist[\"ego\"])).union(set(edgelist[\"alter\"]))\n\n    # Only keep reports made by those who were MARKED as reporters in metadata CSV\n    edgelist = edgelist[edgelist[\"reporter\"].isin(reporters)].copy()\n\n    # Remove self-loops\n    edgelist = edgelist[edgelist[\"ego\"] != edgelist[\"alter\"]].copy()\n\n    # Remove duplicates\n    edgelist.drop_duplicates(inplace=True)\n\n    return edgelist, reporters\n\ndef get_layer(village_id, layer_name, indivinfo, \n              raw_csv_folder=RAW_CSV_FOLDER):\n\n    tie_types = {\n        \"money\": [\"lendmoney\", \"borrowmoney\"],\n        \"advice\": [\"giveadvice\", \"helpdecision\"],\n        \"kerorice\": [\"keroricego\", \"keroricecome\"],\n        \"visit\": [\"visitgo\", \"visitcome\"],\n    }\n\n    selected_tie_types = tie_types[layer_name]\n\n    edgelist = pd.DataFrame()\n    reporters = set()\n\n    for tie_type in selected_tie_types:\n        edgelist_, reporters_ = get_karnataka_survey_data(village_id=village_id, \n                                                            tie_type=tie_type, \n                                                            indivinfo=indivinfo,\n                                                            raw_csv_folder=raw_csv_folder)\n        edgelist = pd.concat([edgelist, edgelist_])\n        reporters = reporters.union(reporters_)\n\n    return edgelist, reporters\n\n\nindivinfo = pd.read_stata(\"datav4.0/Data/2. Demographics and Outcomes/individual_characteristics.dta\")\nindivinfo.drop_duplicates(subset=[\"pid\"], inplace=True) ## one individual (6109803) is repeated twice.\nindivinfo[\"pid\"] = indivinfo[\"pid\"].astype(str)\nindivinfo[\"hhid\"] = indivinfo[\"hhid\"].astype(str)\n\n\nfor i in VALID_VILLAGE_IDS:\n    for layer_name in [\"money\", \"advice\", \"kerorice\", \"visit\"]:\n      print(f\"Processing village {i}\")\n      edgelist, reporters = get_layer(village_id=i, \n                                        layer_name=layer_name, \n                                        indivinfo=indivinfo, \n                                        raw_csv_folder=RAW_CSV_FOLDER)\n      edgelist.to_csv(f\"vil{i}_{layer_name}.csv\", index=False)\n      # save reporters to a separate file\n      pd.DataFrame({\"reporter\": list(reporters)}).to_csv(f\"vil{i}_{layer_name}_reporters.csv\", index=False)\n\n    print(f\"Done with village {i}\")"
  },
  {
    "objectID": "latest/tutorials/python/tutorial01-data-preparation.html#footnotes",
    "href": "latest/tutorials/python/tutorial01-data-preparation.html#footnotes",
    "title": "💻 Tutorial 01: Preparing your data for VIMuRe in python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that the authors provide a different version of the network data on Harvard Dataverse (Banerjee et al. 2013a). However, we will use the raw version provided by Prof. Jackson in this tutorial, as the version of the Dataverse has already had some pre-processing (importantly, they have made the adjacency matrices symmetric), while the version provided by Prof. Jackson gives the original node list. We will use the Harvard Dataverse files just for the metadata.↩︎"
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you will be able to:\nFound an interesting use case for VIMuRe? Let us know! Open a discussion on our GitHub repository."
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#number-of-nodes-and-edges",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#number-of-nodes-and-edges",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "2.1: Number of nodes and edges",
    "text": "2.1: Number of nodes and edges\n\nData Frameigraph object\n\n\nunique_nodes = pd.concat([edgelist['ego'], edgelist['alter']]).unique()\n\nprint(f\"Number of nodes: {len(unique_nodes)}\")\nprint(f\"Number of edges: {len(edgelist)}\")\nwhich yields:\nNumber of nodes: 417\nNumber of edges: 2690\n\n\nprint(f\"Number of nodes: {G.vcount()}\")\nprint(f\"Number of edges: {G.ecount()}\")\nwhich yields:\nNumber of nodes: 417\nNumber of edges: 2690"
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#number-of-reporters",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#number-of-reporters",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "2.2: Number of reporters",
    "text": "2.2: Number of reporters\n\nData Frameigraph object\n\n\nreporters = edgelist[\"reporter\"].unique()\nprint(f\"Number of reporters: {len(reporters)}\")\nNumber of reporters: 203\n\n\nreporters = set(G.es[\"reporter\"])\nprint(f\"Number of reporters: {len(reporters)}\")\nNumber of reporters:  203"
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#average-number-of-ties-per-reporter",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#average-number-of-ties-per-reporter",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "2.3: Average number of ties per reporter",
    "text": "2.3: Average number of ties per reporter\nThere are a couple of things to note about this dataset: reporters could name a maximum of four alters for each question, and reporters can only report on ties that they are involved in (e.g., if a reporter is involved, they cannot report on it). Because we are modelling double-sampled questions, each reporter can report a maximum of 8 ties.\nLet’s create a plot to visualise the distribution of the number of ties per reporter:\n\nData Frameigraph object\n\n\n# Create a plot_df to summarise the number of ties per reporter\n\nplot_df = (\n    edgelist.groupby(['layer', 'tie_type', 'reporter'])\n    .size()\n    .reset_index(name='n_ties')\n    .groupby(['n_ties', 'tie_type', 'layer'])\n    .size()\n    .reset_index(name='n_reporters')\n    .sort_values([\"layer\",  \"n_ties\", \"tie_type\"])\n)\n\n\n# Create a plot_df to summarise the number of ties per reporter\n\nplot_df = (\n    pd.DataFrame({attr: G.es[attr] for attr in [\"reporter\", \"tie_type\", \"layer\"]})\n    .groupby([\"reporter\", \"layer\"])\n    .apply(lambda x: x[\"tie_type\"].value_counts())\n    .reset_index(name=\"n_ties\")\n    .rename(columns={\"level_2\": \"tie_type\"})\n    .groupby([\"n_ties\", \"tie_type\", \"layer\"])\n    .size()\n    .reset_index(name=\"n_reporters\")\n    .sort_values([\"layer\",  \"n_ties\", \"tie_type\"])\n)\n\n\n\nproducing the following table:\n\nLayer adviceLayer keroriceLayer moneyLayer visit\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\ngiveadvice\nadvice\n115\n\n\n1\nhelpdecision\nadvice\n104\n\n\n2\ngiveadvice\nadvice\n45\n\n\n2\nhelpdecision\nadvice\n73\n\n\n3\ngiveadvice\nadvice\n6\n\n\n3\nhelpdecision\nadvice\n13\n\n\n4\ngiveadvice\nadvice\n1\n\n\n4\nhelpdecision\nadvice\n2\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nkeroricecome\nkerorice\n41\n\n\n1\nkeroricego\nkerorice\n42\n\n\n2\nkeroricecome\nkerorice\n99\n\n\n2\nkeroricego\nkerorice\n100\n\n\n3\nkeroricecome\nkerorice\n45\n\n\n3\nkeroricego\nkerorice\n40\n\n\n4\nkeroricecome\nkerorice\n2\n\n\n4\nkeroricego\nkerorice\n4\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nborrowmoney\nmoney\n57\n\n\n1\nlendmoney\nmoney\n66\n\n\n2\nborrowmoney\nmoney\n92\n\n\n2\nlendmoney\nmoney\n86\n\n\n3\nborrowmoney\nmoney\n31\n\n\n3\nlendmoney\nmoney\n16\n\n\n4\nborrowmoney\nmoney\n1\n\n\n\n\n\n\n\n\n\n\nn_ties\ntie_type\nlayer\nn_reporters\n\n\n\n\n1\nvisitcome\nvisit\n45\n\n\n1\nvisitgo\nvisit\n36\n\n\n2\nvisitcome\nvisit\n84\n\n\n2\nvisitgo\nvisit\n67\n\n\n3\nvisitcome\nvisit\n39\n\n\n3\nvisitgo\nvisit\n38\n\n\n4\nvisitcome\nvisit\n11\n\n\n4\nvisitgo\nvisit\n31\n\n\n\n\n\n\n\nAlternatively as a bar plot:\n\n\nClick to show plot code\n\nfrom plotnine import *\n\nplot_df[\"tie_type\"] = pd.Categorical(plot_df[\"tie_type\"], \n                                     categories=[\"visitgo\", \"visitcome\", \n                                                 \"keroricego\", \"keroricecome\", \n                                                 \"borrowmoney\", \"lendmoney\",\n                                                 \"helpdecision\", \"giveadvice\"])\n\nplot_df[\"layer\"] = pd.Categorical(plot_df[\"layer\"], categories=[\"advice\", \"money\", \"kerorice\", \"visit\"])\n\ng = (\n    ggplot(plot_df, aes(x = \"tie_type\", y=\"n_reporters\", fill=\"layer\")) +\n    geom_col() +\n    coord_flip() +\n\n    facet_grid(\"n_ties ~ .\", labeller=\"label_both\") +\n\n    theme_bw() +\n    theme(legend_position = \"bottom\",\n        legend_box_spacing = 0.5) +\n    labs(x = \"Number of ties reported for this prompt\", \n         y = \"Number of reporters\",\n         fill = \"Layer\")\n)\n\nggsave(g, \"tutorial02_fig01.png\", width=6, height=8, dpi=300)\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nNote that the plot above only represents the reports made by the 203 nodes that appear in the reporter column. Given that the total number of nodes in the network is 417, either some nodes did not report on any ties, or they were not interviewed at all.\nVIMuRe will consider all nodes in the network, even if they are not present in the reporter column. If you want to restrict your analysis to include only the network of reporters, you must filter the edge list before proceeding."
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#union-vs.-intersection-and-the-concept-of-concordance",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#union-vs.-intersection-and-the-concept-of-concordance",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "2.4: Union vs. Intersection and the concept of Concordance",
    "text": "2.4: Union vs. Intersection and the concept of Concordance\nConcordance is the proportion of ties in a network that both reporters report. It measures the extent to which the two reporters agree about the tie (see (Ready and Power 2021) for a discussion of concordance in the Karnataka network data). It is calculated as follows:\n\\[\n\\text{Concordance} = \\frac{\\text{\\# of ties reported by both reporters}}{\\text{\\# number of unique ties reported}}\n\\]\n\nData Frameigraph object\n\n\n# Take the intersection: keep only records where \n# both reporters report on the same tie in both tie_types\ndf_intersection = (\n    edgelist.groupby(['ego', 'alter'], dropna=False)\n    .filter(lambda x: len(x) == 2)\n    .loc[:, ['ego', 'alter']]\n    .drop_duplicates()\n)\n\n# Take the union: keep all ties reported \n# irrespective of tie_type and how many times they were reported\ndf_union = edgelist.loc[:, ['ego', 'alter']].drop_duplicates()\n\n# Concordance\nconcordance = len(df_intersection) / len(df_union)\nprint(f\"Concordance is: {concordance}\")\n\n\n# Take the intersection: keep only records where \n# both reporters report on the same tie in both tie_types\nwhich_edges_intersection = [e for e in G.es if G.count_multiple(e) == 2]\n\nG_intersection = G.subgraph_edges(which_edges_intersection)\nG_intersection = G_intersection.simplify()\n\n# Take the union: keep all ties reported \n# irrespective of tie_type and how many times they were reported\nG_union = G.simplify()\n\n# Concordance\nprint(\"Concordance is:\", G_intersection.ecount() / G_union.ecount())\n\n\n\nproducing:\nConcordance is: 0.2002262443438914"
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#posterior-estimates",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#posterior-estimates",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "3.1: Posterior Estimates",
    "text": "3.1: Posterior Estimates\nThe four values you get from the get_posterior_estimates() method are the geometric expectations of the distributions of the following parameters:\n\n\n\n\n\n\n\n\nParameter\nSymbol\nDescription\n\n\n\n\nnu\n\\(\\nu\\)\nThe inferred mutuality for the network (latent equivalent to \\(\\eta\\))\n\n\ntheta\n\\(\\theta_{lm}\\)\nThe “reliability” of a reporter \\(m\\) on layer \\(l\\)\n\n\nlambda\n\\(\\lambda_{lk}\\)\nThe latent contribution that \\(Y_l=k\\) has on \\(\\theta_{lm}\\), where \\(k \\in \\{1, \\ldots, K\\}\\) represents the weight of the tie.\n\n\nrho\n\\(\\rho_{lijk}\\)\nThe probability that a directed tie of weight \\(k-1\\) exists between nodes \\(i\\) and \\(j\\) on a particular layer \\(l\\)\n\n\n\nRemember that the expected value of our model is:\n\\[\n\\mathbb{E} \\left[X_{lijm}^{}|Y_{lij}^{} = k\\right] = \\theta_{lm}\\lambda_{lk}^{}+\\eta X_{ljim}^{}\n\\]\nwhere \\(X_{lijm}^{}\\) is the observed value of the tie between nodes \\(i\\) and \\(j\\) reported by reporter \\(m\\) on layer \\(l\\) and \\(Y_{lij}^{}\\) is the “ground truth” of the strength of the directed tie between nodes \\(i\\) and \\(j\\) on layer \\(l\\).\nIn the subsections below, we will provide an explanation of \\(\\nu\\) and \\(\\theta_{lm}\\) parameters and how to reason about the mutuality and “reliability” of reporters. \\(\\rho\\) and \\(\\lambda\\) are more technical and we will go into detail about them in a future tutorial.\nA quick note about \\(\\rho\\)\nIf you want to extract a quick point estimate of the inferred network, you can simply take the expected value of \\(\\rho\\) for \\(k=1\\):\n# Expected value of rho for k=1\nrho = posterior_estimates['rho'][0,:,:,1]\nThe code above will return a \\(N \\times N\\) weighted adjacency matrix, which can be thought of as the probability of a tie between individuals \\(i\\) and \\(j\\) on layer \\(l = 0\\) (Tutorial 03 will go into more detail about how to interpret the \\(\\rho\\) parameter.)\nNow let’s look at parameters \\(\\nu\\) and \\(\\theta_{lm}\\):\n\n3.1.1: Mutuality (\\(\\nu\\) or \\(\\eta\\))\nIn our case study:\nposterior_estimates['nu']\n0.6177802251078235\nThis indicates a large mutuality in the network. That is, if \\(i\\) reports that \\(j\\) lends money to them, then \\(i\\) is likely to report that \\(j\\) also borrows money from them.\nThis is a network-wide parameter and encompasses all layers. If you have reasons to believe mutuality varies across layers, you have to re-run the model for each layer separately.\n\n\n3.1.2: Under-reporting vs over-reporting: a combination of (\\(\\theta_{lm} \\times \\lambda_{lk}\\))\nFirst, let’s look at the shape of the \\(\\theta\\) array:\nposterior_estimates['theta'].shape\n(4, 417)\nWe have four layers, so the first dimension is 4. The second dimension is the number of reporters in the network. In our case, this shows that VIMuRe infers that there are 417 reporters in the network.\nThis parameter, combined with \\(\\lambda_{lk}\\) represents the “reliability” of a reporter \\(m\\) on layer \\(l\\):\nposterior_estimates['lambda'].shape\n(4, 2)\nThe first dimension is the number of layers \\(l\\), and the second dimension is the strength of the tie, which in this case can assume the values \\(k \\in \\{0, 1\\}\\). We only have two possible values for \\(k\\) because that is the default setting for the VimureModel class. If you want to model more than two possible values for \\(k\\), you can set the K parameter when running the fit function: model.fit(..., K=3).\nThese two parameters combined indicate the probability that a reporter will tend to report ties, in general, for a given layer (recall the expected value of the VIMuRe model shown in Section 3.1: Posterior Estimates). Loosely speaking, we can think of this value as the “reliability” of a reporter on a given layer.\n\n\n\n\n\n\nAnother note on the number of reporters\n\n\n\n\n\nYou might be wondering why there are so many reporters, 417. After all, in Section 2.2: Number of reporters, we calculated this number to be around 200! This is due to a technicality in the way the VIMuRe package handles the data. Our current implementation represents the total number of reporters, \\(M\\) as \\(M = N\\) (i.e. the number of nodes is equal to the number of reporters).\nThis is akin to saying each node has the potential to be a reporter. But to control for which nodes are actually reporters, we use a binary mask, \\(R_{lijm}\\), which is 1 if the node \\(m\\) is a reporter on layer \\(l\\) for the tie between nodes \\(i\\) and \\(j\\) and 0 otherwise. You can control how this mask is built by passing the R parameter to the fit() method. Read more about it in section 3.3: A note on the reporter mask (R).\nChanging this is a priority for the next version of the package. But, as it is not a trivial change, we have decided to leave it as it is for now.\n\n\n\nHow are reporters’ “reliability” distributed across layers?\nLet’s check which reporters have the highest “reliability” values, and plot the values for each layer:\n\n\nClick to see the code\n\n# Get the node mapping: which node corresponds to which index in the array\ndf_nodes = model.nodeNames\n\n# Which nodes are reporters?\n# Note: this assumes you have a `reporters` list from Tutorial 01\nid_reporters = df_nodes[df_nodes['name'].isin(reporters)][\"id\"].values\n\ndf_lambda_k1 = pd.DataFrame(dict(layer=model.layerNames, lambda_k1=posterior_estimates['lambda'][:,1]))\n\n# Add the theta values\ndf_theta_reporters = [\n    (layer_name, reporter_id, df_nodes['name'].iloc[reporter_id], posterior_estimates['theta'][l, reporter_id] * df_lambda_k1['lambda_k1'].iloc[l])\n    for reporter_id in id_reporters\n    for l, layer_name in enumerate(model.layerNames)]\n\ndf_theta_reporters = \\\n    pd.DataFrame(df_theta_reporters, \n                 columns=['layer', 'reporter_id', 'reporter_name', 'theta_scaled'])\n\n# Sort by reliability (scaled by lambda_k=1)\ndf_theta_reporters\\\n    .pivot(index=['reporter_id', 'reporter_name'], \n           columns=['layer'], \n           values=['theta_scaled'])\\\n    .droplevel(0, axis=1)\\\n    .reset_index()\\\n    .sort_values(by=model.layerNames, ascending=False)\\\n    .head()\n\n\n\nClick to see the code\n\n\n# plotnine is the python equivalent of ggplot2\nfrom plotnine import *\n\nplot_df = df_theta_reporters.copy()\n\nCOLORS =  ['#E69F25', '#5CB4E4', '#069F72', '#F1E545', '#0773B2', '#CC79A8']\n\ng = (ggplot(plot_df,  aes(x=\"theta_scaled\", fill=\"layer\")) +\n     geom_histogram(binwidth=0.1, color=\"#212121\") +\n     theme_bw() + \n     facet_grid(\"layer ~ .\", scales=\"free_y\") +\n     scale_fill_manual(values=COLORS, guide=False) +\n     theme(figure_size=(6, 3),\n           axis_text_x=element_text(size=10),\n           axis_text_y=element_text(size=10),\n           panel_grid_minor=element_blank(),\n           panel_grid_major=element_blank(),           \n           strip_background = element_blank(),\n           strip_text_x = element_text(size=10),\n           axis_title=element_text(size=16)) +\n     scale_x_continuous(name=r\"$\\theta \\times \\lambda_{k=1}$\", breaks=np.arange(0, 1.1, 0.1), limits=(0, 1.1)) +\n     scale_y_continuous(name=\"Count\", breaks=np.arange(0, 60, 10), limits=(0, 50)) +\n     ggtitle(r\"Reliability distribution across layers ($\\theta_l \\times \\lambda_{k=1}$)\"))\n\nggsave(g, \"theta_reporters.png\", width=7, height=9, dpi=300)\n\n\nHow should we interpret the values?\nThe interpretation depends on both the mutuality of the network and the survey design. If the mutuality is high (as indicated by \\(\\nu\\) being closer to 1), reporters will naturally tend to reciprocate the ties they report, by default, thus reporters with high \\(\\theta\\) values (relative to the \\(\\theta\\) distribution) are likely “over-reporting” ties.\nLet’s investigate this a bit further by checking the ties reported by a top reporter (113302) in the advice layer:\n\nReporters ranked by advice “reliability”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nreporter_id\nreporter_name\nadvice\nkerorice\nmoney\nvisit\n\n\n\n\n120\n113302\n0.897073\n0.73975\n0.459182\n0.209975\n\n\n124\n113901\n0.878063\n0.820995\n0.868054\n0.669433\n\n\n97\n109902\n0.850442\n0.792795\n1.55569e-05\n0.641589\n\n\n92\n109505\n0.850422\n1.29801e-05\n0.838414\n0.86224\n\n\n56\n105902\n0.850409\n1.27773e-05\n0.458103\n0.37393\n\n\n\n\n\n\n\nMost reporters have reliability in the \\([0.4, 0.6]\\) interval, but 113302 has a “reliability” of \\(\\approx 0.9\\) in the advice layer. Let’s check the ties reported by this reporter:\nedgelist[(edgelist[\"reporter\"] == \"113302\") & (edgelist[\"layer\"] == \"advice\")]\n\nTies reported by 113302 in the layer advice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n113302\n110502\n113302\ngiveadvice\nadvice\n1\n\n\n113302\n113102\n113302\ngiveadvice\nadvice\n1\n\n\n105701\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n110501\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n113601\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n113301\n113302\n113302\nhelpdecision\nadvice\n1\n\n\n\n\n\n\n\nNode 113302 does not report any reciprocal ties, but they do report ties with six other nodes.\nAre all nodes also reporters?\nTwo of these six nodes are not reporters:\nnodes_mentioned = [\"110502\", \"113102\", \"105701\", \"110501\", \"113601\", \"113301\"]\nnot_reporters = [x for x in nodes_mentioned if x not in reporters]\nnot_reporters\n['113102', '105701']\nWe will never be able to confirm ties between 113302 and these nodes and this is already one of the reasons why 113302’s “reliability” is high. (Note that these two non-reporter nodes will have reliability values of \\(\\approx 0\\)).\nOn top of that, when we look at the reports made by the remaining four reporters, only node 113301 confirms the helpdecision tie reported by 113302:\npotential_friends = [\"110502\", \"110501\", \"113601\", \"113301\"]\n\nedgelist[(edgelist['reporter'].isin(potential_friends)) & \n         ((edgelist['ego'] == '113302') | (edgelist['alter'] == '113302'))]\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n113301\n113302\n113301\ngiveadvice\nadvice\n1\n\n\n\nThat is why 113302’s \\(\\theta\\lambda_{k=1}\\) is high: they report a lot of ties, but only one of them is confirmed by other reporters.\nNodes with values in the average range of the \\(\\theta_{lm}\\lambda_{lk}\\) distribution is likely to be more “reliable” reporters."
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#implicit-assumptions",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#implicit-assumptions",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "3.2: Implicit assumptions",
    "text": "3.2: Implicit assumptions\nYou might have noticed the following warning messages when you ran model.fit():\n\nUserWarning: The set of nodes was not informed, using ego and alter columns to infer nodes.\nUserWarning: The set of reporters was not informed, assuming set(reporters) = set(nodes) and N = M.\nUserWarning: Reporters Mask was not informed (parameter R). Parser will build it from reporter column, assuming a reporter can only report their own ties.\n\nThe messages are not errors; they are simply indications that the VIMuRe package has made some implicit assumptions when loading the data. If you would like to set the nodes, and the reporter mask explicitly, you can pass these values as arguments to the fit() method. For example:\nmodel.fit(edgelist, \n          nodes=all_nodes,\n          R=reporter_mask)"
  },
  {
    "objectID": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#a-note-on-the-reporter-mask-r",
    "href": "latest/tutorials/python/tutorial02-introduction-to-vimure.html#a-note-on-the-reporter-mask-r",
    "title": "💻 Tutorial 02: Introduction to VIMuRe in Python",
    "section": "3.3: A note on the reporter mask (R)",
    "text": "3.3: A note on the reporter mask (R)\nWhile nodes and reporters are simple lists of strings, the reporter mask R is a multidimensional sparse logical array (a tensor) with dimensions \\(L \\times N \\times N \\times N\\). Here, R[l, i, j, m] indicates that reporter \\(m\\) can report on the tie between \\(i\\) and \\(j\\) if the tie belongs to layer \\(l\\).\nSo, for example, if the survey design was such that reporters could only report on ties involving themselves, this implies:\n\\[\\begin{cases}\n\nR_{lijm} = 1 & \\text{if } i = m \\text{ or } j = m \\\\\nR_{lijm} = 0 & \\text{otherwise}.\n\n\\end{cases}\\]\nDepending on your survey design, you might want to construct R manually. For example, if all reporters were asked about all ties – regardless of whether they were involved in the ties or not – then R would be a multi-dimensional array of ones. We are planning a future tutorial on how to handle different survey designs.\nIt’s worth noting that currently, the last dimension has size \\(N\\) instead of \\(M\\). This is because the current implementation of the code assumes that all reporters are part of the network. The mathematical model, as described in (De Bacco et al. 2023), is more flexible and supports an arbitrary set of reporters, whether they are a subset of nodes or not. However, we have not yet implemented this functionality in the code. Our survey designs have so far assumed that all reporters are part of the network, so this has not been a problem. If this is a feature you would like to see sooner, let us know by adding a discussion on GitHub."
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "",
    "text": "Note\n\n\n\nIf you use VIMuRe in your research, please cite (De Bacco et al. 2023).\nTLDR: By the end of this tutorial, you will be able to:\nFound an interesting use case for VIMuRe? Let us know! Open a discussion on our GitHub repository."
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html#setup",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html#setup",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "⚙️ Setup",
    "text": "⚙️ Setup\nImport packages\nimport numpy as np\nimport pandas as pd\nimport vimure as vm\nimport igraph as ig\n\nimport matplotlib.pyplot as plt\n⚠️ Ensure you have installed the latest version of VIMuRe before running this tutorial. Follow the 📦 Installation instructions if you haven’t already."
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html#step-1-ensure-you-have-suitable-data-and-a-fitted-vimure-model",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html#step-1-ensure-you-have-suitable-data-and-a-fitted-vimure-model",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "📥 Step 1: Ensure you have suitable data and a fitted VIMuRe model",
    "text": "📥 Step 1: Ensure you have suitable data and a fitted VIMuRe model\nThis tutorial assumes that you have completed 💻 Tutorial 1 and 💻 Tutorial 02 and that, therefore, you have an edgelist data frame and a fitted model object called model loaded in your Python environment.\nWe have selected a particular village to focus on. The dataset contains information on four different types of relationships: money, advice, visit and kerorice. We stored all the data in a single data frame, edgelist, which looks like this:\nedgelist.sample(n=10, random_state=1)\n\n\n\nego\nalter\nreporter\ntie_type\nlayer\nweight\n\n\n\n\n107303\n107307\n107307\nhelpdecision\nadvice\n1\n\n\n116402\n115702\n116402\nkeroricecome\nkerorice\n1\n\n\n103202\n117301\n103202\ngiveadvice\nadvice\n1\n\n\n116201\n110401\n116201\nkeroricecome\nkerorice\n1\n\n\n114606\n109701\n109701\nkeroricego\nkerorice\n1\n\n\n101302\n116201\n101302\nvisitcome\nvisit\n1\n\n\n111204\n110701\n111204\nlendmoney\nmoney\n1\n\n\n108304\n111502\n108304\nkeroricecome\nkerorice\n1\n\n\n117301\n113901\n113901\nborrowmoney\nmoney\n1\n\n\n106201\n116105\n106201\nkeroricecome\nkerorice\n1\n\n\n\nWe then ran VIMuRe on this data frame to fit a latent network model:\nimport vimure as vm\n\n# Run the model\nmodel = vm.model.VimureModel()\nmodel.fit(edgelist)\nIf you have both objects in your environment, you are ready to go!"
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html#step-2-interpreting-the-variable-rho",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html#step-2-interpreting-the-variable-rho",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "📊 Step 2: Interpreting the variable \\(\\rho\\)",
    "text": "📊 Step 2: Interpreting the variable \\(\\rho\\)\nIn this step, our main focus is to analyze the posterior distribution of the latent variable known as rho, which is included in the list of posterior estimates of the model.\nrho = model.get_posterior_estimates()['rho']\n\nrho.shape\n(4, 417, 417, 2)\nThe variable rho is represented as a tensor with dimensions L x N x N x K. Each entry in the tensor can be denoted as \\(\\rho_{lijk}\\), which corresponds to the geometric expectation of the probability of a directed tie with weight \\(k-1\\) existing between nodes \\(i\\) and \\(j\\) on a specific layer \\(l\\).\n\nA note about the parameter \\(K\\)\nThe final dimension of the tensor, denoted by \\(K\\), represents the strength of a tie. By default, the model assumes that the interest is in the presence or absence of ties rather than their weight, resulting in a default value of \\(K=2\\). Consequently, for each potential edge, there are two values of \\(\\rho\\): \\(\\rho_{lijk=1}\\) and \\(\\rho_{lijk=2}\\), corresponding to edges with weights 0 and 1 (\\(k-1\\)) respectively.\nTo make this clearer, let’s consider a specific example. Suppose we want to determine the probability of a directed tie with weight 1 existing between nodes 10 and 15 on layer 1 (‘advice’) of our network. We can examine the following entry in the tensor:\n# rho for layer 1, ego 10, alter 15\nrho[0, 10, 15, :] \nThe result would be:\narray([1.00000000e+00, 4.21007361e-13])\nThis suggests that the model assigns a high probability (approximately 100%) to the absence of a directed tie between nodes 10 and 15 on layer 1 (\\(\\rho_{lijk=1} \\approx 1\\)). Conversely, it assigns a low probability (approximately 0%) to the presence of a directed tie between nodes 10 and 15 on layer 1 (\\(\\rho_{lijk=2} \\approx 0\\)). Based on this, we can conclude that node 10 does not provide advice to node 15.\nIf you are modelling weighted networks, you can specify a different value for \\(K\\), as shown below. Just note that K must be an integer.\n# Fit the model with a different value for K\n\nmodel = vm.model.VimureModel()\nmodel.fit(edgelist, K=10)\n\n\nVisualising rho\nSince the probability of \\(K=1\\) and \\(K=2\\) are complementary, we can plot the probability of a directed tie existing between nodes \\(i\\) and \\(j\\) on layer \\(l\\) as a function of \\(\\rho_{lijk=2}\\). But before we proceed to the plot, let’s take a look at the summary statistics of the values of \\(\\rho\\) per layer:\n\n\nShow code\n\n#The code below converts from adjacency matrix to edge list \n# then summarises the values of rho per layer\npd.concat(\n    [pd.DataFrame(rho[l,:,:,1])\n      .reset_index()\\\n      .melt(id_vars=['index'])\\\n      .assign(l=l)\\\n      .rename(columns={'index':'i', 'variable': 'j'}) \n      for l in range(rho.shape[0])]\n).groupby(['l'])['value'].describe()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nl\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\n0\n173889\n0.00211962\n0.0427501\n1.42201e-13\n3.61097e-13\n4.64657e-13\n6.28092e-13\n1\n\n\n1\n173889\n0.00232455\n0.039379\n1.5432e-13\n5.06778e-13\n7.39753e-13\n8.88974e-13\n0.999831\n\n\n2\n173889\n0.00218808\n0.0409045\n1.45914e-13\n4.10353e-13\n6.37707e-13\n8.39875e-13\n0.999873\n\n\n3\n173889\n0.00253843\n0.0433122\n1.43865e-13\n4.45755e-13\n6.87587e-13\n8.60819e-13\n1\n\n\n\nThe expected values of \\(\\rho\\) are very small, with a mean of approximately 0.002. The inferred network is sparse, as can be expected from a social network of this type. Observe how the minimum value is close but never truly zero, which is a consequence of the Bayesian approach. The standard deviation is also very small, with a mean of approximately 0.04. This suggests that the posterior distribution of \\(\\rho\\) is very concentrated around its mean.\nLet’s look at how the values of \\(\\rho\\) are distributed across layers. We can do this by plotting the distribution of \\(\\rho_{lijk=2}\\) for each layer:\n\n\nShow code\n\nimport igraph as ig\nimport matplotlib.pyplot as plt\n\n# Create a figure with 2 x 2 subplots\nfig, axes = plt.subplots(2,2, figsize=(10,10))\n\n# Loop over the layers\nfor k in range(4):\n    # Get the subplot index\n    i = k // 2\n    j = k % 2\n    # Get the rho matrix for the layer\n    rho_k = rho[k,:,:,1]\n    axes[i,j].imshow(rho_k, vmin=0, vmax=1, cmap='Blues', aspect='equal')\n    axes[i,j].set_xlabel('Alter')\n    axes[i,j].set_ylabel('Ego')\n    # Add a title with the layer name\n    axes[i,j].set_title(f'Layer: {model.layerNames[k]}')\nplt.show()\n\n\n\n\nFigure 1. Distribution of \\(\\rho_{lijk=2}\\)\n\n\nThe plots above give us an idea of how sparse the network is, but without any meaningful node ordering, it’s hard to see its structure. In the next section, we’ll use \\(\\rho_{lijk=2}\\) as a measure of edge strength and treat it as a point estimate for our model. This will help us get a clearer picture of this multi-layered network."
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html#step-3-obtaining-a-simple-point-estimate",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html#step-3-obtaining-a-simple-point-estimate",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "🎲 Step 3: Obtaining a simple point estimate",
    "text": "🎲 Step 3: Obtaining a simple point estimate\nWe can treat the probability values represented by \\(\\rho_{lijk=2}\\) directly as a point estimate, but since most of the entries are very small and none of them are zero, this would lead to a dense network. Instead, it might be more appropriate to apply a thresholding approach and set the lower values to zero.\nHowever, determining the appropriate threshold value \\(t_{\\rho}\\) is not as straightforward as it initially seems. While a suggestion of setting \\(t_{\\rho}=0.5\\) may arise based on the assumption of complementarity between \\(\\rho_{lijk=2}\\) and \\(\\rho_{lijk=1}\\), our research paper (De Bacco et al. 2023, 10–11) reveals the need for adjusting the threshold based on the inferred mutuality, \\(\\eta_{est}\\) (represented by the latent variable \\(\\nu\\)), to achieve a similar level of reciprocity — a network property of interest — as observed in the ground truth network. In other words, tailoring the threshold becomes necessary to ensure that the inferred network accurately captures the desired network property.\nIn the paper, we found that the threshold \\(t_{\\rho}\\) should be set to \\(t_{\\rho} = 0.33 \\times \\eta_{est} + 0.10\\) was a good heuristic to capture reciprocity in simulated synthetic networks with reciprocity. Let’s use this same value here to obtain a point estimate of our network:\nthreshold = 0.33 * model.get_posterior_estimates()['nu'] + 0.10\nthreshold\n0.3075564363103252\nWe can then apply the threshold to the values of \\(\\rho_{lijk=2}\\) to obtain a point estimate of the network:\n# Apply the threshold\nrho_point_estimate = rho[:,:,:,1] &gt; threshold\nTo get the network to look consistent across layers, let’s create a layout from the union of all nodes and edges across layers:\nlayout = (\n    ig.Graph.Adjacency(rho_point_estimate.sum(axis=0).tolist(), mode='directed')\n    .layout_fruchterman_reingold()\n)\n&lt;Layout with 417 vertices and 2 dimensions&gt;\nFinally, we can plot the network using the layout and the thresholded values of \\(\\rho_{lijk=2}\\):\n\n\nShow code\n\n# Create a figure with 2 x 2 subplots\nfig, axes = plt.subplots(2,2, figsize=(10, 7))\naxes = axes.ravel()\n\n# Loop over the layers\nnum_layers = rho_point_estimate.shape[0]\ngs = [ig.Graph.Adjacency(rho_point_estimate[l,:,:].tolist(), mode='directed')\n      for l in range(num_layers)]\n\nvisual_style = {\n    \"edge_width\": 0.6,\n    #\"vertex_size\": 0.8,\n    \"opacity\": 0.7,\n    \"palette\": \"heat\",\n    \"layout\": layout\n}\n\n\nmax_degree = max([max(g.degree()) for g in gs])\n\nfor g, ax in zip(gs, axes):\n    degree = np.array(g.degree())\n    # Scale degree to the interval [0.4 - 1.2]\n    degree = degree / max(degree) * 0.8 + 0.4\n    ig.plot(g, target=ax, vertex_size=degree, **visual_style)\n\nfor l in range(4):\n    # Add a title with the layer name\n    axes[l].set_title(f'Layer: {model.layerNames[l]}')\n\nplt.show()\n\n\n\n\nFigure 2. A point estimate of the four layers of the network, obtained by thresholding \\(\\rho_{lijk=2}\\). Node sizes are scaled according to their degree in the network layer."
  },
  {
    "objectID": "latest/tutorials/python/tutorial03-the-posterior.html#next-steps",
    "href": "latest/tutorials/python/tutorial03-the-posterior.html#next-steps",
    "title": "💻 Tutorial 03: Extracting point estimates from the posterior distribution",
    "section": "Next steps",
    "text": "Next steps\n🚧 TODO: Which network properties can we infer from the networks obtained above?\n🚧 TODO: How does that compare to \\(t_{\\rho}=0.5\\)?"
  }
]