---
title: "ðŸ“š Python package documentation"
subtitle: "VIMuRe v0.1 (latest)"
---
<details><summary>Module `vimure.model`</summary>

# Module `vimure.model`

Inference model

## Functions

### `categorical_elbo_term`


```python
def categorical_elbo_term(rho, prior_rho, EPS):
```

### `gamma_elbo_term`


```python
def gamma_elbo_term(pa, pb, qa, qb):
```

## Classes

### VimureModel


```python
class VimureModel(
    undirected:Â boolÂ =Â False,
    mutuality:Â boolÂ =Â True,
    convergence_tol:Â floatÂ =Â 0.1,
    decision:Â intÂ =Â 1,
    verbose:Â boolÂ =Â False
):
```

**ViMuRe**


Fit a probabilistic generative model to double sampled networks. It returns reliability parameters for the
reporters (theta), average interactions for the links (lambda) and the estimate of the true and unknown
network (rho). The inference is performed with a Variational Inference approach.

Note:â€‚This closely follows the scikit-learn structure of classes:


<https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/_template.py>

**Parameters**

- **``undirected``** : `boolean`

    Whether the network is undirected.
- **``mutuality``** : `boolean`

    Whether to use the mutuality parameter.
- **``convergence_tol``** : `float`

    Controls when to stop the optimisation algorithm (CAVI)

### Ancestors


* sklearn.base.TransformerMixin
* sklearn.utils._set_output._SetOutputMixin
* sklearn.base.BaseEstimator


### Methods

### `calculate_mean_poisson`


```python
def calculate_mean_poisson(
    self,
    G_exp_theta=None,
    G_exp_lambda=None,
    G_exp_nu=None,
    rho=None,
    X_T=None,
    R=None
):
```

### `fit`


```python
def fit(
    self,
    X,
    theta_prior=(0.1, 0.1),
    lambda_prior=(10.0, 10.0),
    eta_prior=(0.5, 1.0),
    rho_prior=None,
    seed:Â intÂ =Â None,
    **extra_params
):
```

**Parameters**

- **``X``** : `ndarray`

    Network adjacency tensor.
- **``theta_prior``** : `2D tuple`

    Shape and scale hyperparameters for variable theta
- **``lambda_prior``** : `2D tuple`

    Shape and scale hyperparameters for variable lambda
- **``eta_prior``** : `2D tuple`

    Shape and scale hyperparameters for variable eta
- **``rho_prior``** : `None/ndarray`

    Array with prior values of the rho parameter - if ndarray.
- **``R``** : `ndarray (optional)`

    a multidimensional array L x N x N x M indicating which reports to consider
- **``K``** : `None/int (optional)`

    Value of the maximum entry of the network - i
- **``EPS``** : `float (optional)`

    White noise. Default: 1e-12
- **``bias0``** : `float (optional)`

    Bias for rho_prior entry 0. Default: 0.2
- **``max_iter``** : `int (optional)`

    Maximum number of iteration steps before aborting. Default=500

**Returns**

`self.rho_f, self.G_exp_theta_f, self.G_exp_lambda_f, self.G_exp_nu_f, self.maxL`
Â 

### `get_inferred_model`


```python
def get_inferred_model(self, method='rho_max', threshold=None):
```

Estimate Y


Use this function to reconstruct the Y matrix with a fitted vimure model.
It will use `model.rho_f` values to extract an estimated Y matrix.


* *rho_max*: Assign the value of the highest probability
* *rho_mean*: Expected value of the discrete distribution
* *fixed_threshold*: Check if the probability is higher than a threshold (Only for K=2)
* *heuristic_threshold*: Calculate and use the best threshold (Only for K=2)


**Parameters**

- **``model``** : `vm.model.VimureModel`

    A `vm.model.VimureModel` object
- **``method``** : `str`

    A character string indicating which method is to be computed.
One of "rho_max" (default), "rho_mean", "fixed_threshold" or "heuristic_threshold".
- **``threshold``** : `float`

    A threshold to be used when method = "fixed_threshold".

**Returns**

- **``Y``** : `ndarray`

    Â 

### `get_posterior_estimates`


```python
def get_posterior_estimates(self):
```

### `sample_inferred_model`


```python
def sample_inferred_model(self, N=1, seed=None):
```

Sample Y trials from rho distribution


Use this function to sample Y trials with a fitted vimure model.
It will use `model.rho_f` as the probabilities of a discrete distribution.


**Parameters**

- **``model``** : `vm.model.VimureModel`

    A `vm.model.VimureModel` object
- **``N``** : `int`

    Number of trials
- **``seed``** : `int`

    A pseudo generator seed

**Returns**

- **``Y``** : `List[ndarray]`

    A list of trials

### `sp_uttkrp_lambda`


```python
def sp_uttkrp_lambda(self, vals, subs):
```

Compute the Khatri-Rao product (sparse version).


**Parameters**

- **``vals``** : `ndarray`

    Values of the non-zero entries.
- **``subs``** : `tuple`

    Indices of elements that are non-zero. It is a n-tuple of array-likes and the length of tuple n must
be equal to the dimension of tensor.

**Returns**

- **``out``** : `ndarray`

    Matrix which is the result of the matrix product of the unfolding of the tensor and the Khatri-Rao
product of the membership matrix.

### `sp_uttkrp_rho`


```python
def sp_uttkrp_rho(self, vals, subs):
```

Compute the Khatri-Rao product (sparse version).


**Parameters**

- **``vals``** : `ndarray`

    Values of the non-zero entries.
- **``subs``** : `tuple`

    Indices of elements that are non-zero. It is a n-tuple of array-likes and the length of tuple n must
be equal to the dimension of tensor.

**Returns**

- **``out``** : `ndarray`

    Matrix which is the result of the matrix product of the unfolding of the tensor and the Khatri-Rao
product of the membership matrix.

### `sp_uttkrp_theta`


```python
def sp_uttkrp_theta(self, vals, subs):
```

Compute the Khatri-Rao product (sparse version).


**Parameters**

- **``vals``** : `ndarray`

    Values of the non-zero entries.
- **``subs``** : `tuple`

    Indices of elements that are non-zero. It is a n-tuple of array-likes and the length of tuple n must
be equal to the dimension of tensor.

**Returns**

- **``out``** : `ndarray`

    Matrix which is the result of the matrix product of the unfolding of the tensor and the Khatri-Rao
product of the membership matrix.



</details>

<details><summary>Module `vimure.synthetic`</summary>

# Module `vimure.synthetic`

Code to generate synthetic networks that emulates directed double-sample questions networks

## Functions

### `build_custom_theta`


```python
def build_custom_theta(
    gt_network:Â [BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork"),
    theta_ratio:Â floatÂ =Â 0.5,
    exaggeration_type:Â strÂ =Â 'over',
    seed:Â intÂ =Â None
):
```

Instead of the regular generative model for `theta ~ Gamma(sh,sc)`,
create a more extreme scenario where some percentage of reporters are exaggerating.


**Parameters**

**`gt_network`** :â€‚[`BaseSyntheticNetwork`](vimure.#vimure.synthetic.BaseSyntheticNetwork)
Generative ground truth model.
- **``theta_ratio``** : `float`

    Percentage of reporters who exaggerate.
- **``exaggeration_type``** : `str`

    ("over", "under")
- **``seed``** : `int`

    If not set, use gt_network.prng instead.

**Returns**

- **``theta``** : `numpy.array`

    A L x M matrix for theta.

### `build_self_reporter_mask`


```python
def build_self_reporter_mask(gt_network):
```

Build the reporters' mask in a way such that:


* A reporter `m` can report ties in which she is ego:
`m --> i`
* A reporter `m` can report ties in which she is alter: `i --> m`
* A reporter `m` **cannot** report ties she is not involved, that is `i --> j` where `i != m` and `j != m`


**Parameters**

**`gt_network`** :â€‚[`BaseSyntheticNetwork`](vimure.#vimure.synthetic.BaseSyntheticNetwork)
Generative ground truth model.

### `transpose_ij`


```python
def transpose_ij(M):
```

Compute the transpose of a matrix.


**Parameters**

- **``M``** : `numpy.array`

    Numpy matrix.

**Returns**


Transpose of the matrix.

## Classes

### BaseSyntheticNetwork


```python
class BaseSyntheticNetwork(
    N:Â intÂ =Â 100,
    M:Â intÂ =Â 100,
    L:Â intÂ =Â 1,
    K:Â intÂ =Â 2,
    seed:Â intÂ =Â 0,
    **kwargs
):
```

A base abstract class for generation and management of synthetic networks.
Suitable for representing any type of synthetic network (whether SBM or not).


**Parameters**

- **``N``** : `int`

    Number of nodes.
- **``M``** : `int`

    Number of reporters.
- **``L``** : `int`

    Number of layers.
- **``K``** : `int`

    Maximum edge weight in the adjacency matrix.
When `K=2`, the adjacency matrix will contain some `Y_{ij}=0` and `Y_{ij}=1`.
- **``seed``** : `int`

    Pseudo random generator seed to use.

### Ancestors


* vimure._io.BaseNetwork


### Subclasses


* [HollandLaskeyLeinhardtModel](#vimure.synthetic.HollandLaskeyLeinhardtModel "vimure.synthetic.HollandLaskeyLeinhardtModel")
* [StandardSBM](#vimure.synthetic.StandardSBM "vimure.synthetic.StandardSBM")


### Methods

### `build_X`


```python
def build_X(
    self,
    mutuality:Â floatÂ =Â 0.5,
    sh_theta:Â floatÂ =Â 2.0,
    sc_theta:Â floatÂ =Â 0.5,
    flag_self_reporter:Â boolÂ =Â True,
    cutoff_X:Â boolÂ =Â False,
    lambda_diff:Â floatÂ =Â None,
    Q:Â intÂ =Â None,
    seed:Â intÂ =Â None,
    theta:Â numpy.ndarrayÂ =Â None,
    verbose:Â boolÂ =Â False
):
```

Any object inhereted from BaseSyntheticNetwork will have a ground truth network Y.
Given that Y, generate the observed network X.


**Parameters**

- **``mutuality``** : `float`

    The mutuality parameter from 0 to 1.
- **``sh_theta``** : `float`

    Shape of gamma distribution from which to draw theta.
The 'reliability' of nodes is represented by the parameter `theta_{lm}`
and by default are modelled as a gamma function with shape `sh_theta` and scale `sc_theta`.
- **``sc_theta``** : `float`

    Scale of gamma distribution from which to draw theta.
- **``flag_self_reporter``** : `bool`

    Indicates whether a node can only report about their own ties.
- **``Q``** : `int`

    Maximum value of X entries. If None, it will use the network's K parameter.
- **``cutoff_X``** : `bool`

    Whether to set X as a binary.
- **``lambda_diff``** : `float`

    The difference between each subsequent K.
- **``seed``** : `int`

    Pseudo random generator seed to use.
- **``verbose``** : `bool`

    Provides additional details.

**Returns**

- **``X``** : `sktensor`

    Observed network.

### `build_Y`


```python
def build_Y(self):
```

### `generate_lv`


```python
def generate_lv(self):
```

### DegreeCorrectedSBM


```python
class DegreeCorrectedSBM(
    exp_in:Â floatÂ =Â 2,
    exp_out:Â floatÂ =Â 2.5,
    **kwargs
):
```

**Degree-corrected stochastic blockmodel.**


A generative model that incorporates heterogeneous vertex degrees into stochastic blockmodels, improving the performance of the models for statistical inference of group structure.
For more information about this model, see Karrer, B., & Newman, M. E. (2011). *Stochastic blockmodels and community structure in networks*. Physical review E, 83(1), 016107.
[DOI:10.1103/PhysRevE.83.016107](https://arxiv.org/pdf/1008.3926.pdf).


**Parameters**

- **``exp_in``** : `float`

    Exponent power law of in-degree distribution.
- **``exp_out``** : `float`

    Exponent power law of out-degree distribution.
**`kwargs`**
Additional arguments of [`StandardSBM`](vimure.#vimure.synthetic.StandardSBM)

### Ancestors


* [StandardSBM](#vimure.synthetic.StandardSBM "vimure.synthetic.StandardSBM")
* [BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")
* vimure._io.BaseNetwork


### Methods

### `generate_lv`


```python
def generate_lv(self):
```

Overwrite standard SBM model to add degree distribution

### Inherited members


* `**[StandardSBM](#vimure.synthetic.StandardSBM "vimure.synthetic.StandardSBM")**`:
	+ [`build_X`](vimure.#vimure.synthetic.BaseSyntheticNetwork.build_X)
	+ [`build_Y`](vimure.#vimure.synthetic.StandardSBM.build_Y)
	+ [`init_sbm_params`](vimure.#vimure.synthetic.StandardSBM.init_sbm_params)

### HollandLaskeyLeinhardtModel


```python
class HollandLaskeyLeinhardtModel(**kwargs):
```

A base abstract class for generation and management of synthetic networks.
Suitable for representing any type of synthetic network (whether SBM or not).


**Parameters**

- **``N``** : `int`

    Number of nodes.
- **``M``** : `int`

    Number of reporters.
- **``L``** : `int`

    Number of layers.
- **``K``** : `int`

    Maximum edge weight in the adjacency matrix.
When `K=2`, the adjacency matrix will contain some `Y_{ij}=0` and `Y_{ij}=1`.
- **``seed``** : `int`

    Pseudo random generator seed to use.

### Ancestors


* [BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")
* vimure._io.BaseNetwork


### Inherited members


* `**[BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")**`:
	+ [`build_X`](vimure.#vimure.synthetic.BaseSyntheticNetwork.build_X)

### Multitensor


```python
class Multitensor(eta=0.5, ExpM=None, **kwargs):
```

**A generative model with reciprocity**


A mathematically principled generative model for capturing both community and reciprocity patterns in directed networks.
Adapted from Safdari H., Contisciani M. & De Bacco C. (2021). Generative model for reciprocity and community detection in networks, Phys. Rev. Research 3, 023209.
[DOI:10.1103/PhysRevResearch.3.023209](https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.3.023209).


Generate a directed, possibly weighted network by using the reciprocity generative model.
Can be used to generate benchmarks for networks with reciprocity.


## Steps


1. Generate the latent variables.
2. Extract `A_{ij}` entries (network edges) from a Poisson distribution; its mean depends on the latent variables.

Note:â€‚Open Source code available at <https://github.com/mcontisc/CRep> and modified in accordance with its [license](https://github.com/mcontisc/CRep/blob/master/LICENSE).

---


Copyright (c) 2020 Hadiseh Safdari, Martina Contisciani and Caterina De Bacco.


**Parameters**

- **``eta``** : `float`

    Initial value for the reciprocity coefficient. Eta has to be in [0, 1).
- **``ExpM``** : `int`

    Expected number of edges
**`kwargs`**
Additional arguments of [`StandardSBM`](vimure.#vimure.synthetic.StandardSBM)

### Ancestors


* [StandardSBM](#vimure.synthetic.StandardSBM "vimure.synthetic.StandardSBM")
* [BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")
* vimure._io.BaseNetwork


### Methods

### `Exp_ija_matrix`


```python
def Exp_ija_matrix(self, u, v, w):
```

Compute the mean lambda0_ij for all entries.


**Parameters**

- **``u``** : `numpy.array`

    Out-going membership matrix.
- **``v``** : `numpy.array`

    In-coming membership matrix.
- **``w``** : `numpy.array`

    Affinity matrix.

**Returns**

- **``M``** : `numpy.array`

    Mean `lambda^{0}_{ij}` for all entries.

### `build_Y`


```python
def build_Y(self):
```

Generate network layers G and adjacency matrix A using the latent variables,
with the generative model `(A_{ij},A_{ji}) ~ P(A_{ij}|u,v,w,eta) P(A_{ji}|A_{ij},u,v,w,eta)`

### Inherited members


* `**[StandardSBM](#vimure.synthetic.StandardSBM "vimure.synthetic.StandardSBM")**`:
	+ [`build_X`](vimure.#vimure.synthetic.BaseSyntheticNetwork.build_X)
	+ [`generate_lv`](vimure.#vimure.synthetic.StandardSBM.generate_lv)
	+ [`init_sbm_params`](vimure.#vimure.synthetic.StandardSBM.init_sbm_params)

### StandardSBM


```python
class StandardSBM(
    C:Â intÂ =Â 2,
    structure:Â strÂ =Â None,
    avg_degree:Â floatÂ =Â 2,
    sparsify:Â boolÂ =Â True,
    overlapping:Â floatÂ =Â 0.0,
    **kwargs
):
```

**Creates a standard stochastic block-model synthetic network.**


A generative graph model which assumes the probability of connecting two nodes in a graph is determined entirely by their block assignments.
For more information about this model, see Holland, P. W., Laskey, K. B., & Leinhardt, S. (1983). *Stochastic blockmodels: First steps. Social networks*, 5(2), 109-137.
[DOI:10.1016/0378-8733(83)90021-7](https://www.sciencedirect.com/science/article/abs/pii/0378873383900217)


**Parameters**

- **``C``** : `int`

    Number of communities
- **``structure``** : `str`

    Structures for the affinity tensor `w`. It can be 'assortative' or 'disassortative'.
It can be a list to map structure for each layer in a multilayer graph.
- **``avg_degree``** : `float`

    Desired average degree for the network. It is not guaranteed that the
ultimate network will have that exact average degree value.
Try tweaking this parameter if you want to increase or decrease the
density of the network.
- **``sparsify``** : `bool`

    If True (default), enforce sparsity.
- **``overlapping``** : `float`

    Fraction of nodes with mixed membership. It has to be in [`0, 1)`.
**`kwargs`**
Additional arguments of `[StandardSBM`](vimure.#vimure.synthetic.StandardSBM)

### Ancestors


* [BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")
* vimure._io.BaseNetwork


### Subclasses


* [DegreeCorrectedSBM](#vimure.synthetic.DegreeCorrectedSBM "vimure.synthetic.DegreeCorrectedSBM")
* [Multitensor](#vimure.synthetic.Multitensor "vimure.synthetic.Multitensor")


### Methods

### `build_Y`


```python
def build_Y(self):
```

Latent variables

### `generate_lv`


```python
def generate_lv(self):
```

Generate latent variables for a Stochastic BlockModel, assuming network layers are independent.

### `init_sbm_params`


```python
def init_sbm_params(self, **kwargs):
```

Check SBM-specific parameters

### Inherited members


* `**[BaseSyntheticNetwork](#vimure.synthetic.BaseSyntheticNetwork "vimure.synthetic.BaseSyntheticNetwork")**`:
	+ [`build_X`](vimure.#vimure.synthetic.BaseSyntheticNetwork.build_X)



</details>

<details><summary>Module `vimure.utils`</summary>

# Module `vimure.utils`

## Functions

### `apply_rho_threshold`


```python
def apply_rho_threshold(model, threshold=None):
```

Apply a threshold to binarise the rho matrix and return the recovered Y

### `calculate_AUC`


```python
def calculate_AUC(pred, data0, mask=None):
```

Return the AUC of the link prediction. It represents the probability that a randomly chosen missing connection
(true positive) is given a higher score by our method than a randomly chosen pair of unconnected vertices
(true negative).


**Parameters**

- **``pred``** : `ndarray`

    Inferred values.
- **``data0``** : `ndarray`

    Given values.
- **``mask``** : `ndarray`

    Mask for selecting a subset of the adjacency tensor.

**Returns**


AUC value.

### `calculate_average_over_reporter_mask`


```python
def calculate_average_over_reporter_mask(X, R):
```

### `calculate_overall_reciprocity`


```python
def calculate_overall_reciprocity(Y):
```

### `get_item_array_from_subs`


```python
def get_item_array_from_subs(A, ref_subs):
```

Get values of ref_subs entries of a dense tensor.
Output is a 1-d array with dimension = number of non zero entries.

### `get_optimal_threshold`


```python
def get_optimal_threshold(model):
```

<https://arxiv.org/pdf/2112.11396.pdf> pg 8

### `is_sparse`


```python
def is_sparse(X):
```

Check whether the input tensor is sparse.
It implements a heuristic definition of sparsity. A tensor is considered sparse if:
given
M = number of modes
S = number of entries
I = number of non-zero entries
then
N > M(I + 1)


**Parameters**

- **``X``** : `ndarray`

    Input data.

**Returns**


Boolean flag: true if the input tensor is sparse, false otherwise.

### `match_arg`


```python
def match_arg(x, lst):
```

### `preprocess`


```python
def preprocess(X):
```

Pre-process input data tensor.
If the input is sparse, returns an int sptensor. Otherwise, returns an int dtensor.


**Parameters**

- **``X``** : `ndarray/list`

    Input data.

**Returns**

- **``X``** : `sptensor/dtensor`

    Pre-processed data. If the input is sparse, returns an int sptensor. Otherwise, returns an int dtensor.

### `sparse_max`


```python
def sparse_max(A, B):
```

Return the element-wise maximum of sparse matrices `A` and `B`.

### `sptensor_from_dense_array`


```python
def sptensor_from_dense_array(X):
```

Create an sptensor from a ndarray or dtensor.


**Parameters**

- **``X``** : `ndarray`

    Input data.

**Returns**


sptensor from a ndarray or dtensor.

### `sptensor_from_list`


```python
def sptensor_from_list(X):
```

Create an sptensor a sptensor from a list.


Assuming it is a list of dimensions L x M with sparse matrices as elements



</details>

